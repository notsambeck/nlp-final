{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForPermutationLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    LineByLineWithRefDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = './hfcache'\n",
    "MODEL_NAME = 'google/electra-small-generator'\n",
    "MODIFIED_MODEL = './electra_plus_contrast_mlm/'\n",
    "config = AutoConfig.from_pretrained(MODIFIED_MODEL, cache_dir=CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128, padding_idx=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    MODIFIED_MODEL,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=CACHE,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'huggingface is creating a thing that the community uses to solve nlp tasks.',\n",
       "  'score': 0.1659284383058548,\n",
       "  'token': 2518,\n",
       "  'token_str': 'thing'},\n",
       " {'sequence': 'huggingface is creating a one that the community uses to solve nlp tasks.',\n",
       "  'score': 0.08882203698158264,\n",
       "  'token': 2028,\n",
       "  'token_str': 'one'},\n",
       " {'sequence': 'huggingface is creating a lake that the community uses to solve nlp tasks.',\n",
       "  'score': 0.07363732159137726,\n",
       "  'token': 2697,\n",
       "  'token_str': 'lake'},\n",
       " {'sequence': 'huggingface is creating a quilt that the community uses to solve nlp tasks.',\n",
       "  'score': 0.06791206449270248,\n",
       "  'token': 27565,\n",
       "  'token_str': 'quilt'},\n",
       " {'sequence': 'huggingface is creating a umbrella that the community uses to solve nlp tasks.',\n",
       "  'score': 0.05017251521348953,\n",
       "  'token': 12977,\n",
       "  'token_str': 'umbrella'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"HuggingFace is creating a {tokenizer.mask_token} that the community uses to solve NLP tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'dan is very tall. dan is not tall.',\n",
       "  'score': 0.9813898205757141,\n",
       "  'token': 4206,\n",
       "  'token_str': 'tall'},\n",
       " {'sequence': 'dan is very tall. dan is not short.',\n",
       "  'score': 0.005566936451941729,\n",
       "  'token': 2460,\n",
       "  'token_str': 'short'},\n",
       " {'sequence': 'dan is very tall. dan is not small.',\n",
       "  'score': 0.0019572521559894085,\n",
       "  'token': 2235,\n",
       "  'token_str': 'small'},\n",
       " {'sequence': 'dan is very tall. dan is not fat.',\n",
       "  'score': 0.0010749083012342453,\n",
       "  'token': 6638,\n",
       "  'token_str': 'fat'},\n",
       " {'sequence': 'dan is very tall. dan is not big.',\n",
       "  'score': 0.0009656721958890557,\n",
       "  'token': 2502,\n",
       "  'token_str': 'big'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"Dan is very tall.  Dan is not {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'i thought that mark was smart, but instead he was very smart.',\n",
       "  'score': 0.7903743386268616,\n",
       "  'token': 6047,\n",
       "  'token_str': 'smart'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very stupid.',\n",
       "  'score': 0.17495791614055634,\n",
       "  'token': 5236,\n",
       "  'token_str': 'stupid'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very intelligent.',\n",
       "  'score': 0.005439497996121645,\n",
       "  'token': 9414,\n",
       "  'token_str': 'intelligent'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very wise.',\n",
       "  'score': 0.0017061398830264807,\n",
       "  'token': 7968,\n",
       "  'token_str': 'wise'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very brave.',\n",
       "  'score': 0.0014950091717764735,\n",
       "  'token': 9191,\n",
       "  'token_str': 'brave'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"I thought that Mark was smart, but instead he was very {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'i wanted a fun toy, but i got a good one instead.',\n",
       "  'score': 0.029720524325966835,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a stupid one instead.',\n",
       "  'score': 0.02953438088297844,\n",
       "  'token': 5236,\n",
       "  'token_str': 'stupid'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a easy one instead.',\n",
       "  'score': 0.028891297057271004,\n",
       "  'token': 3733,\n",
       "  'token_str': 'easy'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a polite one instead.',\n",
       "  'score': 0.024854343384504318,\n",
       "  'token': 13205,\n",
       "  'token_str': 'polite'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a smart one instead.',\n",
       "  'score': 0.01905311644077301,\n",
       "  'token': 6047,\n",
       "  'token_str': 'smart'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"I wanted a fun toy, but I got a {tokenizer.mask_token} one instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'the day was excessively beautiful, but she had been hoping for a beautiful one instead.',\n",
       "  'score': 0.6622408032417297,\n",
       "  'token': 3376,\n",
       "  'token_str': 'beautiful'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a ugly one instead.',\n",
       "  'score': 0.11599694192409515,\n",
       "  'token': 9200,\n",
       "  'token_str': 'ugly'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a stupid one instead.',\n",
       "  'score': 0.013757024891674519,\n",
       "  'token': 5236,\n",
       "  'token_str': 'stupid'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a salty one instead.',\n",
       "  'score': 0.011508408933877945,\n",
       "  'token': 23592,\n",
       "  'token_str': 'salty'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a nasty one instead.',\n",
       "  'score': 0.009772603400051594,\n",
       "  'token': 11808,\n",
       "  'token_str': 'nasty'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"The day was excessively beautiful, but she had been hoping for a {tokenizer.mask_token} one instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=CACHE,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "p = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'huggingface is creating a system that the community uses to solve nlp tasks.',\n",
       "  'score': 0.15001358091831207,\n",
       "  'token': 2291,\n",
       "  'token_str': 'system'},\n",
       " {'sequence': 'huggingface is creating a tool that the community uses to solve nlp tasks.',\n",
       "  'score': 0.120941162109375,\n",
       "  'token': 6994,\n",
       "  'token_str': 'tool'},\n",
       " {'sequence': 'huggingface is creating a solution that the community uses to solve nlp tasks.',\n",
       "  'score': 0.06042460724711418,\n",
       "  'token': 5576,\n",
       "  'token_str': 'solution'},\n",
       " {'sequence': 'huggingface is creating a database that the community uses to solve nlp tasks.',\n",
       "  'score': 0.053126465529203415,\n",
       "  'token': 7809,\n",
       "  'token_str': 'database'},\n",
       " {'sequence': 'huggingface is creating a computer that the community uses to solve nlp tasks.',\n",
       "  'score': 0.03361189365386963,\n",
       "  'token': 3274,\n",
       "  'token_str': 'computer'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"HuggingFace is creating a {tokenizer.mask_token} that the community uses to solve NLP tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'dan is very tall. dan is not tall.',\n",
       "  'score': 0.3833930492401123,\n",
       "  'token': 4206,\n",
       "  'token_str': 'tall'},\n",
       " {'sequence': 'dan is very tall. dan is not strong.',\n",
       "  'score': 0.0479818657040596,\n",
       "  'token': 2844,\n",
       "  'token_str': 'strong'},\n",
       " {'sequence': 'dan is very tall. dan is not big.',\n",
       "  'score': 0.03165790066123009,\n",
       "  'token': 2502,\n",
       "  'token_str': 'big'},\n",
       " {'sequence': 'dan is very tall. dan is not taller.',\n",
       "  'score': 0.028651991859078407,\n",
       "  'token': 12283,\n",
       "  'token_str': 'taller'},\n",
       " {'sequence': 'dan is very tall. dan is not long.',\n",
       "  'score': 0.024816956371068954,\n",
       "  'token': 2146,\n",
       "  'token_str': 'long'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"Dan is very tall.  Dan is not {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'i thought that mark was smart, but instead he was very smart.',\n",
       "  'score': 0.6189573407173157,\n",
       "  'token': 6047,\n",
       "  'token_str': 'smart'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very intelligent.',\n",
       "  'score': 0.039767418056726456,\n",
       "  'token': 9414,\n",
       "  'token_str': 'intelligent'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very good.',\n",
       "  'score': 0.026786595582962036,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very clever.',\n",
       "  'score': 0.017436936497688293,\n",
       "  'token': 12266,\n",
       "  'token_str': 'clever'},\n",
       " {'sequence': 'i thought that mark was smart, but instead he was very young.',\n",
       "  'score': 0.01190208736807108,\n",
       "  'token': 2402,\n",
       "  'token_str': 'young'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"I thought that Mark was smart, but instead he was very {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'i wanted a fun toy, but i got a new one instead.',\n",
       "  'score': 0.24864517152309418,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a fun one instead.',\n",
       "  'score': 0.08383011817932129,\n",
       "  'token': 4569,\n",
       "  'token_str': 'fun'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a little one instead.',\n",
       "  'score': 0.05334790423512459,\n",
       "  'token': 2210,\n",
       "  'token_str': 'little'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a good one instead.',\n",
       "  'score': 0.048895809799432755,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good'},\n",
       " {'sequence': 'i wanted a fun toy, but i got a cute one instead.',\n",
       "  'score': 0.029207438230514526,\n",
       "  'token': 10140,\n",
       "  'token_str': 'cute'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"I wanted a fun toy, but I got a {tokenizer.mask_token} one instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'the day was excessively beautiful, but she had been hoping for a better one instead.',\n",
       "  'score': 0.17477267980575562,\n",
       "  'token': 2488,\n",
       "  'token_str': 'better'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a new one instead.',\n",
       "  'score': 0.1298745721578598,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a good one instead.',\n",
       "  'score': 0.06588517874479294,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a bigger one instead.',\n",
       "  'score': 0.04379922151565552,\n",
       "  'token': 7046,\n",
       "  'token_str': 'bigger'},\n",
       " {'sequence': 'the day was excessively beautiful, but she had been hoping for a different one instead.',\n",
       "  'score': 0.04136064276099205,\n",
       "  'token': 2367,\n",
       "  'token_str': 'different'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"The day was excessively beautiful, but she had been hoping for a {tokenizer.mask_token} one instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
