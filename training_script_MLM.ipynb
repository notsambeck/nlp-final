{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5aae6c",
   "metadata": {},
   "source": [
    "# MLM training\n",
    "\n",
    "adapted from\n",
    "https://huggingface.co/transformers/v2.5.1/examples.html#language-model-training\n",
    "and\n",
    "https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "\n",
    "```\n",
    "export TRAIN_FILE=/path/to/dataset/wiki.train.raw\n",
    "export TEST_FILE=/path/to/dataset/wiki.test.raw\n",
    "\n",
    "python run_language_modeling.py \\\n",
    "    --output_dir=output \\\n",
    "    --model_type=roberta \\\n",
    "    --model_name_or_path=roberta-base \\\n",
    "    --do_train \\\n",
    "    --train_data_file=$TRAIN_FILE \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=$TEST_FILE \\\n",
    "    --mlm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367e420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForPermutationLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    LineByLineWithRefDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    pipeline\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8592453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = './hfcache'\n",
    "MODEL_NAME = 'google/electra-small-discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a826e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME, cache_dir=CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37593b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984e1819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForMaskedLM: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['generator_lm_head.weight', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128, padding_idx=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=CACHE,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885b4c0",
   "metadata": {},
   "source": [
    "# build standard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc118c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/sambeck/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de6961",
   "metadata": {},
   "source": [
    "### A. tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86711adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = d.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"], )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81b398",
   "metadata": {},
   "source": [
    "### B. stick examples together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b301eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0ded55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca645fa0",
   "metadata": {},
   "source": [
    "### (tokenizer check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7313d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24169293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1026b70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"to achieve this, the cooperative elements incorporated into the second game were removed, as they took up a large portion of memory space needed for the improvements. they also adjusted the difficulty settings and ease of play so they could appeal to new players while retaining the essential components of the series'gameplay. the newer systems were decided upon early in development. the character designs were done by raita honjou, who had worked on the previous valkyria chronicles games. when creating the nameless squad, honjou was faced with the same problem he had had during the first game : the military uniforms essentially destroyed character individuality, despite him needing to create\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][17]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18c455c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK] salary'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([103, 10300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a9eee",
   "metadata": {},
   "source": [
    "### build collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb746d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05a8313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92068444",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70616381",
   "metadata": {},
   "source": [
    "### Note that trainer stores data intact - dataloader does the masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1956f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 102,\n",
       " 101,\n",
       " 1027,\n",
       " 11748,\n",
       " 4801,\n",
       " 4360,\n",
       " 11906,\n",
       " 3523,\n",
       " 1027,\n",
       " 102,\n",
       " 101,\n",
       " 102,\n",
       " 101,\n",
       " 12411,\n",
       " 5558,\n",
       " 2053,\n",
       " 11748,\n",
       " 4801,\n",
       " 4360,\n",
       " 1017,\n",
       " 1024,\n",
       " 4895,\n",
       " 2890,\n",
       " 27108,\n",
       " 5732,\n",
       " 11906,\n",
       " 1006,\n",
       " 2887,\n",
       " 1024,\n",
       " 1856,\n",
       " 1806,\n",
       " 1671,\n",
       " 30222,\n",
       " 30218,\n",
       " 30259,\n",
       " 30227,\n",
       " 30255,\n",
       " 30258,\n",
       " 30219,\n",
       " 2509,\n",
       " 1010,\n",
       " 5507,\n",
       " 1012,\n",
       " 11748,\n",
       " 4801,\n",
       " 4360,\n",
       " 1997,\n",
       " 1996,\n",
       " 11686,\n",
       " 1017,\n",
       " 1007,\n",
       " 1010,\n",
       " 4141,\n",
       " 3615,\n",
       " 2000,\n",
       " 2004,\n",
       " 11748,\n",
       " 4801,\n",
       " 4360,\n",
       " 11906,\n",
       " 3523,\n",
       " 2648,\n",
       " 2900,\n",
       " 1010,\n",
       " 2003,\n",
       " 1037,\n",
       " 8608,\n",
       " 2535,\n",
       " 1030,\n",
       " 1011,\n",
       " 1030,\n",
       " 2652,\n",
       " 2678,\n",
       " 2208,\n",
       " 2764,\n",
       " 2011,\n",
       " 16562,\n",
       " 1998,\n",
       " 2865,\n",
       " 1012,\n",
       " 4432,\n",
       " 2005,\n",
       " 1996,\n",
       " 9160,\n",
       " 12109,\n",
       " 1012,\n",
       " 2207,\n",
       " 1999,\n",
       " 2254,\n",
       " 2249,\n",
       " 1999,\n",
       " 2900,\n",
       " 1010,\n",
       " 2009,\n",
       " 2003,\n",
       " 1996,\n",
       " 2353,\n",
       " 2208,\n",
       " 1999,\n",
       " 1996,\n",
       " 11748,\n",
       " 4801,\n",
       " 4360,\n",
       " 2186,\n",
       " 1012,\n",
       " 15440,\n",
       " 1996,\n",
       " 2168,\n",
       " 10077,\n",
       " 1997,\n",
       " 8608,\n",
       " 1998,\n",
       " 2613,\n",
       " 1030,\n",
       " 1011,\n",
       " 1030,\n",
       " 2051,\n",
       " 11247,\n",
       " 2004,\n",
       " 2049,\n",
       " 16372,\n",
       " 1010,\n",
       " 1996,\n",
       " 2466,\n",
       " 3216,\n",
       " 5903,\n",
       " 2000]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18480c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'input_ids': tensor([[  103,  1024,   102,  ...,  2025,  2035,  1996],\n",
      "        [ 7164,  1996,  2177,  ...,  1006,  9122,  4027],\n",
      "        [ 5228,  3037,  1999,  ...,  2623,   103,  2709],\n",
      "        ...,\n",
      "        [15037,   103,  1037,  ...,  1999,  1996,  4470],\n",
      "        [ 2000,  3824,  5491,  ...,  2029,  2387,  3163],\n",
      "        [ 3033,   103,  3469,  ...,  2025, 12599,  9932]]), 'labels': tensor([[10176,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  2177,  ...,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  ...,  -100,  2010,  -100],\n",
      "        ...,\n",
      "        [ -100,  1010,  -100,  ...,  -100,  -100,  -100],\n",
      "        [ -100,  -100,  -100,  ...,  -100,  -100,  -100],\n",
      "        [ -100,  1997,  -100,  ...,  -100,  -100,  -100]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# what happens inside train:\n",
    "dl = trainer.get_train_dataloader()\n",
    "for batch in dl:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d2386fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids', 'labels', 'token_type_ids'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea570795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  103,  1024,   102,   101,  1440,  1006, 25957,  2072,  1007,  2089,\n",
       "         2022,   103,  2066,  1443,  5436, 19354,  2072,   103,  2007,  1037,\n",
       "         2701,  7077,  2012,  1996,  3953,  1012,   102,   101,  1441,  1006,\n",
       "         2123,  2072, 22906,  2003,  4703,  2517,  2007,   103,  3722,  7077,\n",
       "         2012,  2327,  1010,  1012,   102,   101,  1446,  1010,   100,  1010,\n",
       "         1998,   100,  1006,  1047,  1005,   103,  2072,  1010, 24529,  7088,\n",
       "         1010,  1040,  5831,  3669,  1007,  2024,   103,  2517,  2007,   103,\n",
       "          103,  7471,   103,  2012,  1996,  2327,  1010,   103,   103,  2005,\n",
       "         2742,   100,   103, 24529,  7088,  1007, 12950,  1037,  1057,  2007,\n",
       "         1037, 11737, 10814,  1999,  1996,  2157,  2217,  1012,   102,   101,\n",
       "          103,   103,  5869,  2072,  1007,  2003,   103,  2517,  2007,   103,\n",
       "          103,  8115,   103,  1012,   103,  2043,  2035,  2093,  2024,  2517,\n",
       "         1010,  2027,  1005,  2128,   103,  2025,  2035,  1996])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15% tokens replaced\n",
    "batch['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d86dd906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10176,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  2517,  -100,  -100,  1006,  -100,  -100,  1007,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  1007,  -100,  -100,  -100,  -100,  1037,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  2019,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  3227,  -100,  -100,  3442,\n",
       "         1010,  -100,  3210,  -100,  -100,  -100,  -100,  2061,  2008,  -100,\n",
       "         -100,  -100,  1006,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         1447,  1006,  -100,  -100,  -100,  -100,  4703,  -100,  -100,  1037,\n",
       "         2309,  -100,  1010,  -100,  2130,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  3227,  -100,  -100,  -100])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only masked tokens are labeled\n",
    "batch['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e1ff8",
   "metadata": {},
   "source": [
    "# train / evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b535d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 18535\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6951\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6951' max='6951' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6951/6951 15:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.359800</td>\n",
       "      <td>6.031094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.728800</td>\n",
       "      <td>5.545131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.579000</td>\n",
       "      <td>5.497122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-1000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-1000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-1500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-1500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-2000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-2000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1921\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-2500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-2500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-3000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-3000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-3500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-3500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-4000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-4000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-4500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-4500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1921\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-5000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-5000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-5500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-5500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-6000\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-6000/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to finetuned-wikitext2/checkpoint-6500\n",
      "Configuration saved in finetuned-wikitext2/checkpoint-6500/config.json\n",
      "Model weights saved in finetuned-wikitext2/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1921\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6951, training_loss=6.119051658203406, metrics={'train_runtime': 929.3451, 'train_samples_per_second': 59.832, 'train_steps_per_second': 7.479, 'total_flos': 408857383503360.0, 'train_loss': 6.119051658203406, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98ca401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=128, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a25e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30420e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'huggingface is creating a song that the community uses to solve nlp tasks.',\n",
       "  'score': 0.003066012868657708,\n",
       "  'token': 2299,\n",
       "  'token_str': 'song'},\n",
       " {'sequence': 'huggingface is creating a game that the community uses to solve nlp tasks.',\n",
       "  'score': 0.0021496417466551065,\n",
       "  'token': 2208,\n",
       "  'token_str': 'game'},\n",
       " {'sequence': 'huggingface is creating a role that the community uses to solve nlp tasks.',\n",
       "  'score': 0.0019248999888077378,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role'},\n",
       " {'sequence': 'huggingface is creating a character that the community uses to solve nlp tasks.',\n",
       "  'score': 0.0018462331499904394,\n",
       "  'token': 2839,\n",
       "  'token_str': 'character'},\n",
       " {'sequence': 'huggingface is creating a film that the community uses to solve nlp tasks.',\n",
       "  'score': 0.0017241048626601696,\n",
       "  'token': 2143,\n",
       "  'token_str': 'film'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"HuggingFace is creating a {tokenizer.mask_token} that the community uses to solve NLP tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74990106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
