{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e833e60d",
   "metadata": {},
   "source": [
    "# MLM training on standard MLM masking, following training on our data\n",
    "\n",
    "adapted from\n",
    "https://huggingface.co/transformers/v2.5.1/examples.html#language-model-training\n",
    "and\n",
    "https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d45a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    DataCollatorWithPadding,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    LineByLineWithRefDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    pipeline\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = './hfcache'\n",
    "MODEL_NAME = './model-mlm-generated-text/checkpoint-35000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb1ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME, cache_dir=CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589347d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99efb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128, padding_idx=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=CACHE,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3453c",
   "metadata": {},
   "source": [
    "# build standard MLM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d90159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-103-raw-v1 (download: 183.09 MiB, generated: 523.97 MiB, post-processed: Unknown size, total: 707.06 MiB) to /home/sambeck/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f9e87b45c4165ac044b29e4ebf886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to /home/sambeck/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_dataset('wikitext', 'wikitext-103-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394ab44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1801350\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df227b8d",
   "metadata": {},
   "source": [
    "### A. tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83d432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee39154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = d.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"], )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692975f1",
   "metadata": {},
   "source": [
    "### B. Build x,y for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8add1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop,\n",
    "    # you can customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f04dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a339ae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 2199\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 916424\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 1921\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f444b",
   "metadata": {},
   "source": [
    "### (tokenizer check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5372998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a26c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b340ce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s battle system, the blitz system, is carried over directly from valkyira chronicles. during missions, players select each unit using a top @ - @ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @ - @ person. a character can only act once per @ - @ turn, but characters can be granted multiple turns at the expense of other characters'turns. each character has a field and distance of movement limited by their action gauge. up to nine characters can be assigned to a single mission. during gameplay, characters will call out if something happens to them, such\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][5]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c71123a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "1027\n",
      "1027\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "4360\n",
      "4360\n",
      "11906\n",
      "11906\n",
      "3523\n",
      "3523\n",
      "1027\n",
      "1027\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "12411\n",
      "12411\n",
      "5558\n",
      "5558\n",
      "2053\n",
      "2053\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "4360\n",
      "4360\n",
      "1017\n",
      "1017\n",
      "1024\n",
      "1024\n",
      "4895\n",
      "4895\n",
      "2890\n",
      "2890\n",
      "27108\n",
      "27108\n",
      "5732\n",
      "5732\n",
      "11906\n",
      "11906\n",
      "1006\n",
      "1006\n",
      "2887\n",
      "2887\n",
      "1024\n",
      "1024\n",
      "1856\n",
      "1856\n",
      "1806\n",
      "1806\n",
      "1671\n",
      "1671\n",
      "30222\n",
      "30222\n",
      "30218\n",
      "30218\n",
      "30259\n",
      "30259\n",
      "30227\n",
      "30227\n",
      "30255\n",
      "30255\n",
      "30258\n",
      "30258\n",
      "30219\n",
      "30219\n",
      "2509\n",
      "2509\n",
      "1010\n",
      "1010\n",
      "5507\n",
      "5507\n",
      "1012\n",
      "1012\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "4360\n",
      "4360\n",
      "1997\n",
      "1997\n",
      "1996\n",
      "1996\n",
      "11686\n",
      "11686\n",
      "1017\n",
      "1017\n",
      "1007\n",
      "1007\n",
      "1010\n",
      "1010\n",
      "4141\n",
      "4141\n",
      "3615\n",
      "3615\n",
      "2000\n",
      "2000\n",
      "2004\n",
      "2004\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "4360\n",
      "4360\n",
      "11906\n",
      "11906\n",
      "3523\n",
      "3523\n",
      "2648\n",
      "2648\n",
      "2900\n",
      "2900\n",
      "\n",
      " 1\n",
      "1996\n",
      "1996\n",
      "2034\n",
      "2034\n",
      "2208\n",
      "2208\n",
      "1998\n",
      "1998\n",
      "4076\n",
      "4076\n",
      "1996\n",
      "1996\n",
      "1000\n",
      "1000\n",
      "2171\n",
      "2171\n",
      "3238\n",
      "3238\n",
      "1000\n",
      "1000\n",
      "1010\n",
      "1010\n",
      "1037\n",
      "1037\n",
      "18476\n",
      "18476\n",
      "2510\n",
      "2510\n",
      "3131\n",
      "3131\n",
      "3529\n",
      "3529\n",
      "1996\n",
      "1996\n",
      "3842\n",
      "3842\n",
      "1997\n",
      "1997\n",
      "26033\n",
      "26033\n",
      "2401\n",
      "2401\n",
      "2076\n",
      "2076\n",
      "1996\n",
      "1996\n",
      "2117\n",
      "2117\n",
      "12124\n",
      "12124\n",
      "2078\n",
      "2078\n",
      "2162\n",
      "2162\n",
      "2040\n",
      "2040\n",
      "4685\n",
      "4685\n",
      "3595\n",
      "3595\n",
      "2304\n",
      "2304\n",
      "3136\n",
      "3136\n",
      "1998\n",
      "1998\n",
      "2024\n",
      "2024\n",
      "25895\n",
      "25895\n",
      "2114\n",
      "2114\n",
      "1996\n",
      "1996\n",
      "4461\n",
      "4461\n",
      "3131\n",
      "3131\n",
      "1000\n",
      "1000\n",
      "10250\n",
      "10250\n",
      "8067\n",
      "8067\n",
      "3723\n",
      "3723\n",
      "10000\n",
      "10000\n",
      "1000\n",
      "1000\n",
      "1012\n",
      "1012\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "1996\n",
      "1996\n",
      "2208\n",
      "2208\n",
      "2211\n",
      "2211\n",
      "2458\n",
      "2458\n",
      "1999\n",
      "1999\n",
      "2230\n",
      "2230\n",
      "1010\n",
      "1010\n",
      "4755\n",
      "4755\n",
      "2058\n",
      "2058\n",
      "1037\n",
      "1037\n",
      "2312\n",
      "2312\n",
      "4664\n",
      "4664\n",
      "1997\n",
      "1997\n",
      "1996\n",
      "1996\n",
      "2147\n",
      "2147\n",
      "2589\n",
      "2589\n",
      "\n",
      " 2\n",
      "11472\n",
      "11472\n",
      "10830\n",
      "10830\n",
      "1012\n",
      "1012\n",
      "1037\n",
      "1037\n",
      "2312\n",
      "2312\n",
      "2136\n",
      "2136\n",
      "1997\n",
      "1997\n",
      "4898\n",
      "4898\n",
      "8971\n",
      "8971\n",
      "1996\n",
      "1996\n",
      "5896\n",
      "5896\n",
      "1012\n",
      "1012\n",
      "1996\n",
      "1996\n",
      "2208\n",
      "2208\n",
      "1005\n",
      "1005\n",
      "1055\n",
      "1055\n",
      "3098\n",
      "3098\n",
      "4323\n",
      "4323\n",
      "2001\n",
      "2001\n",
      "7042\n",
      "7042\n",
      "2011\n",
      "2011\n",
      "2089\n",
      "2089\n",
      "1005\n",
      "1005\n",
      "1050\n",
      "1050\n",
      "1012\n",
      "1012\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "2009\n",
      "2009\n",
      "2777\n",
      "2777\n",
      "2007\n",
      "2007\n",
      "3893\n",
      "3893\n",
      "4341\n",
      "4341\n",
      "1999\n",
      "1999\n",
      "2900\n",
      "2900\n",
      "1010\n",
      "1010\n",
      "1998\n",
      "1998\n",
      "2001\n",
      "2001\n",
      "5868\n",
      "5868\n",
      "2011\n",
      "2011\n",
      "2119\n",
      "2119\n",
      "2887\n",
      "2887\n",
      "1998\n",
      "1998\n",
      "2530\n",
      "2530\n",
      "4401\n",
      "4401\n",
      "1012\n",
      "1012\n",
      "2044\n",
      "2044\n",
      "2713\n",
      "2713\n",
      "1010\n",
      "1010\n",
      "2009\n",
      "2009\n",
      "2363\n",
      "2363\n",
      "26720\n",
      "26720\n",
      "4180\n",
      "4180\n",
      "1010\n",
      "1010\n",
      "2247\n",
      "2247\n",
      "2007\n",
      "2007\n",
      "2019\n",
      "2019\n",
      "4423\n",
      "4423\n",
      "3179\n",
      "3179\n",
      "1999\n",
      "1999\n",
      "2281\n",
      "2281\n",
      "1997\n",
      "1997\n",
      "2008\n",
      "2008\n",
      "2095\n",
      "2095\n",
      "1012\n",
      "1012\n",
      "\n",
      " 3\n",
      "4360\n",
      "4360\n",
      "1024\n",
      "1024\n",
      "24296\n",
      "24296\n",
      "4329\n",
      "4329\n",
      "2005\n",
      "2005\n",
      "1996\n",
      "1996\n",
      "9160\n",
      "9160\n",
      "1018\n",
      "1018\n",
      "1012\n",
      "1012\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "1027\n",
      "1027\n",
      "1027\n",
      "1027\n",
      "11247\n",
      "11247\n",
      "1027\n",
      "1027\n",
      "1027\n",
      "1027\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "102\n",
      "102\n",
      "101\n",
      "101\n",
      "2004\n",
      "2004\n",
      "2007\n",
      "2007\n",
      "3025\n",
      "3025\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "7895\n",
      "7895\n",
      "11906\n",
      "11906\n",
      "2399\n",
      "2399\n",
      "1010\n",
      "1010\n",
      "11748\n",
      "11748\n",
      "4801\n",
      "4801\n",
      "4360\n",
      "4360\n",
      "11906\n",
      "11906\n",
      "3523\n",
      "3523\n",
      "2003\n",
      "2003\n",
      "1037\n",
      "1037\n",
      "8608\n",
      "8608\n",
      "2535\n",
      "2535\n",
      "1030\n",
      "1030\n",
      "1011\n",
      "1011\n",
      "1030\n",
      "1030\n",
      "2652\n",
      "2652\n",
      "2208\n",
      "2208\n",
      "2073\n",
      "2073\n",
      "2867\n",
      "2867\n",
      "2202\n",
      "2202\n",
      "2491\n",
      "2491\n",
      "1997\n",
      "1997\n",
      "1037\n",
      "1037\n",
      "2510\n",
      "2510\n",
      "3131\n",
      "3131\n",
      "1998\n",
      "1998\n",
      "2202\n",
      "2202\n",
      "2112\n",
      "2112\n",
      "1999\n",
      "1999\n",
      "6416\n",
      "6416\n",
      "2114\n",
      "2114\n",
      "4099\n",
      "4099\n",
      "2749\n",
      "2749\n",
      "1012\n",
      "1012\n",
      "3441\n",
      "3441\n",
      "2024\n",
      "2024\n",
      "\n",
      " 4\n",
      "3295\n",
      "3295\n",
      "2006\n",
      "2006\n",
      "1996\n",
      "1996\n",
      "4949\n",
      "4949\n",
      "9783\n",
      "9783\n",
      "5834\n",
      "5834\n",
      "2006\n",
      "2006\n",
      "2019\n",
      "2019\n",
      "3265\n",
      "3265\n",
      "2447\n",
      "2447\n",
      "1005\n",
      "1005\n",
      "1055\n",
      "1055\n",
      "3921\n",
      "3921\n",
      "1024\n",
      "1024\n",
      "2043\n",
      "2043\n",
      "2028\n",
      "2028\n",
      "5724\n",
      "5724\n",
      "2003\n",
      "2003\n",
      "3479\n",
      "3479\n",
      "1010\n",
      "1010\n",
      "1996\n",
      "1996\n",
      "2060\n",
      "2060\n",
      "2003\n",
      "2003\n",
      "10203\n",
      "10203\n",
      "2125\n",
      "2125\n",
      "2000\n",
      "2000\n",
      "1996\n",
      "1996\n",
      "2447\n",
      "2447\n",
      "1012\n",
      "1012\n",
      "2648\n",
      "2648\n",
      "6416\n",
      "6416\n",
      "1010\n",
      "1010\n",
      "1996\n",
      "1996\n",
      "2447\n",
      "2447\n",
      "3494\n",
      "3494\n",
      "2717\n",
      "2717\n",
      "1999\n",
      "1999\n",
      "1037\n",
      "1037\n",
      "3409\n",
      "3409\n",
      "1010\n",
      "1010\n",
      "2073\n",
      "2073\n",
      "3197\n",
      "3197\n",
      "2064\n",
      "2064\n",
      "2022\n",
      "2022\n",
      "28749\n",
      "28749\n",
      "1998\n",
      "1998\n",
      "2839\n",
      "2839\n",
      "3930\n",
      "3930\n",
      "5158\n",
      "5158\n",
      "1012\n",
      "1012\n",
      "4077\n",
      "4077\n",
      "1996\n",
      "1996\n",
      "2364\n",
      "2364\n",
      "2466\n",
      "2466\n",
      "6416\n",
      "6416\n",
      "2024\n",
      "2024\n",
      "2839\n",
      "2839\n",
      "1030\n",
      "1030\n",
      "1011\n",
      "1011\n",
      "1030\n",
      "1030\n",
      "3563\n",
      "3563\n",
      "4942\n",
      "4942\n",
      "6416\n",
      "6416\n",
      "8800\n",
      "8800\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    _x = lm_datasets['train'][i]['input_ids']\n",
    "    _y = lm_datasets['train'][i]['labels']\n",
    "    print('\\n', i)\n",
    "    for i in range(64):\n",
    "        print(_x[i])\n",
    "        print(_y[i])\n",
    "        if _y[i] == -0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c4a6c",
   "metadata": {},
   "source": [
    "### build collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b772d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b1ccc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"model-mlm-generated-text\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "#     evaluate_during_training=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=100,\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36c20134",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f84770",
   "metadata": {},
   "source": [
    "### This trainer stores data masked - dataloader does nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1415101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = trainer.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc377c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'input_ids': tensor([[ 2008,  1996,  5156,  ...,  5195,  1006,  4690],\n",
      "        [13182,   102,   101,  ..., 28176,  1998,  3782],\n",
      "        [23453,  1012,   102,  ...,  1012,   103,  2003],\n",
      "        ...,\n",
      "        [  103,  2005,  1996,  ...,  3164,  2135,  1010],\n",
      "        [  102,   101,  1027,  ...,  2106,  5149,  1005],\n",
      "        [ 8865,  1006,  2432,  ...,  2072,  1010,  2040]]), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [1012, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, 2009, -100],\n",
      "        ...,\n",
      "        [1006, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for s in dl:\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189d28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sample(i):\n",
    "    _x = s['input_ids'][i]\n",
    "    _y = s['labels'][i]\n",
    "    print('\\n', i)\n",
    "    for j in range(64):\n",
    "        print(_x[j])\n",
    "        print(_y[j])\n",
    "        if _y[j] == 0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee7a612",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 7\n",
      "tensor(8865)\n",
      "tensor(-100)\n",
      "tensor(1006)\n",
      "tensor(-100)\n",
      "tensor(2432)\n",
      "tensor(-100)\n",
      "tensor(1007)\n",
      "tensor(-100)\n",
      "tensor(1010)\n",
      "tensor(-100)\n",
      "tensor(2310)\n",
      "tensor(-100)\n",
      "tensor(103)\n",
      "tensor(10139)\n",
      "tensor(2140)\n",
      "tensor(-100)\n",
      "tensor(1006)\n",
      "tensor(-100)\n",
      "tensor(2294)\n",
      "tensor(-100)\n",
      "tensor(1007)\n",
      "tensor(-100)\n",
      "tensor(1010)\n",
      "tensor(-100)\n",
      "tensor(9587)\n",
      "tensor(-100)\n",
      "tensor(19436)\n",
      "tensor(-100)\n",
      "tensor(1006)\n",
      "tensor(-100)\n",
      "tensor(2289)\n",
      "tensor(-100)\n",
      "tensor(1007)\n",
      "tensor(-100)\n",
      "tensor(1998)\n",
      "tensor(-100)\n",
      "tensor(11968)\n",
      "tensor(-100)\n",
      "tensor(14317)\n",
      "tensor(-100)\n",
      "tensor(103)\n",
      "tensor(3512)\n",
      "tensor(23169)\n",
      "tensor(-100)\n",
      "tensor(1006)\n",
      "tensor(-100)\n",
      "tensor(2289)\n",
      "tensor(-100)\n",
      "tensor(1007)\n",
      "tensor(-100)\n",
      "tensor(1012)\n",
      "tensor(-100)\n",
      "tensor(2178)\n",
      "tensor(-100)\n",
      "tensor(6232)\n",
      "tensor(-100)\n",
      "tensor(2013)\n",
      "tensor(-100)\n",
      "tensor(1996)\n",
      "tensor(-100)\n",
      "tensor(7560)\n",
      "tensor(-100)\n",
      "tensor(1010)\n",
      "tensor(-100)\n",
      "tensor(7680)\n",
      "tensor(-100)\n",
      "tensor(4183)\n",
      "tensor(-100)\n",
      "tensor(1038)\n",
      "tensor(-100)\n",
      "tensor(12707)\n",
      "tensor(-100)\n",
      "tensor(2696)\n",
      "tensor(-100)\n",
      "tensor(7507)\n",
      "tensor(-100)\n",
      "tensor(2099)\n",
      "tensor(-100)\n",
      "tensor(16963)\n",
      "tensor(-100)\n",
      "tensor(1010)\n",
      "tensor(-100)\n",
      "tensor(2404)\n",
      "tensor(-100)\n",
      "tensor(1996)\n",
      "tensor(-100)\n",
      "tensor(2143)\n",
      "tensor(-100)\n",
      "tensor(103)\n",
      "tensor(1999)\n",
      "tensor(2223)\n",
      "tensor(-100)\n",
      "tensor(2007)\n",
      "tensor(-100)\n",
      "tensor(2060)\n",
      "tensor(-100)\n",
      "tensor(103)\n",
      "tensor(2558)\n",
      "tensor(3152)\n",
      "tensor(-100)\n",
      "tensor(2066)\n",
      "tensor(-100)\n",
      "tensor(1996)\n",
      "tensor(-100)\n",
      "tensor(2702)\n",
      "tensor(-100)\n",
      "tensor(3094)\n",
      "tensor(-100)\n",
      "tensor(13665)\n",
      "tensor(-100)\n",
      "tensor(28140)\n",
      "tensor(2015)\n",
      "tensor(1006)\n",
      "tensor(-100)\n",
      "tensor(3838)\n",
      "tensor(-100)\n",
      "tensor(1007)\n",
      "tensor(-100)\n",
      "tensor(3841)\n",
      "tensor(-100)\n",
      "tensor(1030)\n",
      "tensor(-100)\n",
      "tensor(1011)\n",
      "tensor(-100)\n",
      "tensor(1030)\n",
      "tensor(-100)\n",
      "tensor(15876)\n",
      "tensor(-100)\n"
     ]
    }
   ],
   "source": [
    "view_sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e1e0b",
   "metadata": {},
   "source": [
    "# train / evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d5e638b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 916424\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 114553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5234' max='114553' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5234/114553 11:50 < 4:07:27, 7.36 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-1000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-1000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-1500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-1500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-2000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-2000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-2500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-2500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-3000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-3000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-3500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-3500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-4000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-4000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-4500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-4500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-5000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-5000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-5000/special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                             nn.utils.clip_grad_norm_(\n\u001b[1;32m   1313\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m                             )\n\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04c28f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a25e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "036a0b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'it is not cold, it must be hot.',\n",
       "  'score': 0.9281871914863586,\n",
       "  'token': 2980,\n",
       "  'token_str': 'hot'},\n",
       " {'sequence': 'it is not cold, it must be cold.',\n",
       "  'score': 0.011733351275324821,\n",
       "  'token': 3147,\n",
       "  'token_str': 'cold'},\n",
       " {'sequence': 'it is not cold, it must be warm.',\n",
       "  'score': 0.006822537165135145,\n",
       "  'token': 4010,\n",
       "  'token_str': 'warm'},\n",
       " {'sequence': 'it is not cold, it must be good.',\n",
       "  'score': 0.004887840244919062,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good'},\n",
       " {'sequence': 'it is not cold, it must be cool.',\n",
       "  'score': 0.0036937883123755455,\n",
       "  'token': 4658,\n",
       "  'token_str': 'cool'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"It is not cold, it must be {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1872ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model_trained_on_generated_then_wiki\n",
      "Configuration saved in ./model_trained_on_generated_then_wiki/config.json\n",
      "Model weights saved in ./model_trained_on_generated_then_wiki/pytorch_model.bin\n",
      "tokenizer config file saved in ./model_trained_on_generated_then_wiki/tokenizer_config.json\n",
      "Special tokens file saved in ./model_trained_on_generated_then_wiki/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./model_trained_on_generated_then_wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ea047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
