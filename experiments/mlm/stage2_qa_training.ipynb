{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275c34b1",
   "metadata": {},
   "source": [
    "# train the model for QA\n",
    "\n",
    "* was previously trained on our MLM data\n",
    "* now traing for QA task on standard SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de9c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser, pipeline\n",
    "from helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "\n",
    "NUM_PREPROCESSING_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c81cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp/experiments/mlm\n"
     ]
    }
   ],
   "source": [
    "cd experiments/mlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='./model/'\n",
    "TASK='qa'\n",
    "DATASET='squad'\n",
    "MAX_LENGTH=128\n",
    "TRAIN_MAX_SAMPLES=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cd2e4",
   "metadata": {},
   "source": [
    "### compare new Checklist-based dataset with Squad\n",
    "\n",
    "(you can make a basic Checklist dataset using the make_checklist_dataset notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e56381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "sqd = datasets.load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d198fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sqd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f65e6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4833e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model/ were not used when initializing ElectraForQuestionAnswering: ['generator_predictions.LayerNorm.bias', 'generator_lm_head.bias', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at ./model/ and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class = AutoModelForQuestionAnswering\n",
    "# Initialize the model and tokenizer from the specified pretrained model/checkpoint\n",
    "model = model_class.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05a1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model pipeline (includes tokenization)\n",
    "mp = pipeline(\"question-answering\", tokenizer=tokenizer, model=model, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfb0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.040087077766656876, 'start': 9, 'end': 10, 'answer': 'a'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebfe4e",
   "metadata": {},
   "source": [
    "### Set up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bcccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_featurized = None\n",
    "eval_dataset_featurized = None\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32481ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-f7c1b765c5a3e631.arrow\n",
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-ced7c06ba114c9f3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-647933d23d01e8b5.arrow\n",
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-c6a30d2b93d27863.arrow\n"
     ]
    }
   ],
   "source": [
    "prepare_train_dataset = lambda exs: prepare_train_dataset_qa(exs, tokenizer)\n",
    "prepare_eval_dataset = lambda exs: prepare_validation_dataset_qa(exs, tokenizer)\n",
    "\n",
    "if TRAIN_MAX_SAMPLES:\n",
    "    train_dataset = train_dataset.select(range(TRAIN_MAX_SAMPLES))\n",
    "\n",
    "print('featurize train...')\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "    prepare_train_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print('featurize test...')\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "    prepare_eval_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "144cb7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224fc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_class = Trainer\n",
    "eval_kwargs = {}\n",
    "# If you want to use custom metrics, you should define your own \"compute_metrics\" function.\n",
    "# For an example of a valid compute_metrics function, see compute_accuracy in helpers.py.\n",
    "compute_metrics = None\n",
    "# For QA, we need to use a tweaked version of the Trainer (defined in helpers.py)\n",
    "# to enable the question-answering specific evaluation metrics\n",
    "trainer_class = QuestionAnsweringTrainer\n",
    "eval_kwargs['eval_examples'] = eval_dataset\n",
    "metric = datasets.load_metric('squad')\n",
    "compute_metrics = lambda eval_preds: metric.compute(\n",
    "    predictions=eval_preds.predictions, references=eval_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2628dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function wraps the compute_metrics function, storing the model's predictions\n",
    "# so that they can be dumped along with the computed metrics\n",
    "eval_predictions = None\n",
    "def compute_metrics_and_store_predictions(eval_preds):\n",
    "    global eval_predictions\n",
    "    eval_predictions = eval_preds\n",
    "    return compute_metrics(eval_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738b3f4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer object with the specified arguments and the model and dataset we loaded above\n",
    "trainer = trainer_class(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_featurized,\n",
    "    eval_dataset=eval_dataset_featurized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_and_store_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a30b27c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 87714\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32895' max='32895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32895/32895 2:49:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.546900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.538200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.328500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.297800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.323100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.118800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>1.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>1.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>1.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.911200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.866300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.915100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.883200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.851200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.885600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-500\n",
      "Configuration saved in tmp_trainer/checkpoint-500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1000\n",
      "Configuration saved in tmp_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1500\n",
      "Configuration saved in tmp_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2000\n",
      "Configuration saved in tmp_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2500\n",
      "Configuration saved in tmp_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3000\n",
      "Configuration saved in tmp_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3500\n",
      "Configuration saved in tmp_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4000\n",
      "Configuration saved in tmp_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4500\n",
      "Configuration saved in tmp_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5000\n",
      "Configuration saved in tmp_trainer/checkpoint-5000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5500\n",
      "Configuration saved in tmp_trainer/checkpoint-5500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6000\n",
      "Configuration saved in tmp_trainer/checkpoint-6000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6500\n",
      "Configuration saved in tmp_trainer/checkpoint-6500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7000\n",
      "Configuration saved in tmp_trainer/checkpoint-7000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7500\n",
      "Configuration saved in tmp_trainer/checkpoint-7500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8000\n",
      "Configuration saved in tmp_trainer/checkpoint-8000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8500\n",
      "Configuration saved in tmp_trainer/checkpoint-8500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9000\n",
      "Configuration saved in tmp_trainer/checkpoint-9000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9500\n",
      "Configuration saved in tmp_trainer/checkpoint-9500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10000\n",
      "Configuration saved in tmp_trainer/checkpoint-10000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10500\n",
      "Configuration saved in tmp_trainer/checkpoint-10500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11000\n",
      "Configuration saved in tmp_trainer/checkpoint-11000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11500\n",
      "Configuration saved in tmp_trainer/checkpoint-11500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12000\n",
      "Configuration saved in tmp_trainer/checkpoint-12000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in tmp_trainer/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12500\n",
      "Configuration saved in tmp_trainer/checkpoint-12500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13000\n",
      "Configuration saved in tmp_trainer/checkpoint-13000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13500\n",
      "Configuration saved in tmp_trainer/checkpoint-13500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14000\n",
      "Configuration saved in tmp_trainer/checkpoint-14000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14500\n",
      "Configuration saved in tmp_trainer/checkpoint-14500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15000\n",
      "Configuration saved in tmp_trainer/checkpoint-15000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15500\n",
      "Configuration saved in tmp_trainer/checkpoint-15500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16000\n",
      "Configuration saved in tmp_trainer/checkpoint-16000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16500\n",
      "Configuration saved in tmp_trainer/checkpoint-16500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17000\n",
      "Configuration saved in tmp_trainer/checkpoint-17000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17500\n",
      "Configuration saved in tmp_trainer/checkpoint-17500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18000\n",
      "Configuration saved in tmp_trainer/checkpoint-18000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18500\n",
      "Configuration saved in tmp_trainer/checkpoint-18500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19000\n",
      "Configuration saved in tmp_trainer/checkpoint-19000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19500\n",
      "Configuration saved in tmp_trainer/checkpoint-19500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20000\n",
      "Configuration saved in tmp_trainer/checkpoint-20000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20500\n",
      "Configuration saved in tmp_trainer/checkpoint-20500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21000\n",
      "Configuration saved in tmp_trainer/checkpoint-21000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21500\n",
      "Configuration saved in tmp_trainer/checkpoint-21500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22000\n",
      "Configuration saved in tmp_trainer/checkpoint-22000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22500\n",
      "Configuration saved in tmp_trainer/checkpoint-22500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23000\n",
      "Configuration saved in tmp_trainer/checkpoint-23000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23500\n",
      "Configuration saved in tmp_trainer/checkpoint-23500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in tmp_trainer/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24000\n",
      "Configuration saved in tmp_trainer/checkpoint-24000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24500\n",
      "Configuration saved in tmp_trainer/checkpoint-24500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25000\n",
      "Configuration saved in tmp_trainer/checkpoint-25000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25500\n",
      "Configuration saved in tmp_trainer/checkpoint-25500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26000\n",
      "Configuration saved in tmp_trainer/checkpoint-26000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26500\n",
      "Configuration saved in tmp_trainer/checkpoint-26500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27000\n",
      "Configuration saved in tmp_trainer/checkpoint-27000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27500\n",
      "Configuration saved in tmp_trainer/checkpoint-27500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28000\n",
      "Configuration saved in tmp_trainer/checkpoint-28000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28500\n",
      "Configuration saved in tmp_trainer/checkpoint-28500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29000\n",
      "Configuration saved in tmp_trainer/checkpoint-29000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29500\n",
      "Configuration saved in tmp_trainer/checkpoint-29500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30000\n",
      "Configuration saved in tmp_trainer/checkpoint-30000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30500\n",
      "Configuration saved in tmp_trainer/checkpoint-30500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31000\n",
      "Configuration saved in tmp_trainer/checkpoint-31000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31500\n",
      "Configuration saved in tmp_trainer/checkpoint-31500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32000\n",
      "Configuration saved in tmp_trainer/checkpoint-32000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32500\n",
      "Configuration saved in tmp_trainer/checkpoint-32500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32895, training_loss=1.1865316144853653, metrics={'train_runtime': 10187.9535, 'train_samples_per_second': 25.829, 'train_steps_per_second': 3.229, 'total_flos': 7688358702452736.0, 'train_loss': 1.1865316144853653, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "761c9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7661155462265015, 'start': 11, 'end': 16, 'answer': 'black'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd68e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7975326180458069, 'start': 24, 'end': 28, 'answer': 'John'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is the most awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cbb7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9565076231956482, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32962747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6610851883888245, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is least hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46663893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6676932573318481, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is not hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f589e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf0e79e",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf46d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model-qa-trained\n",
      "Configuration saved in ./model-qa-trained/config.json\n",
      "Model weights saved in ./model-qa-trained/pytorch_model.bin\n",
      "tokenizer config file saved in ./model-qa-trained/tokenizer_config.json\n",
      "Special tokens file saved in ./model-qa-trained/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./model-qa-trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
