{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e833e60d",
   "metadata": {},
   "source": [
    "# MLM training on our generated data\n",
    "\n",
    "adapted from\n",
    "https://huggingface.co/transformers/v2.5.1/examples.html#language-model-training\n",
    "and\n",
    "https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d45a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    DataCollatorWithPadding,\n",
    "    HfArgumentParser,\n",
    "    LineByLineTextDataset,\n",
    "    LineByLineWithRefDataset,\n",
    "    PreTrainedTokenizer,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    pipeline\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = './hfcache'\n",
    "MODEL_NAME = 'google/electra-small-generator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb1ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME, cache_dir=CACHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589347d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99efb367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128, padding_idx=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=CACHE,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3453c",
   "metadata": {},
   "source": [
    "# build new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0ff969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./contrast_dataset/data.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d90159",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394ab44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['x', 'y', '__index_level_0__'],\n",
       "    num_rows: 111556\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443ce64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('She knew that Jimmy was way too [MASK], but in this instance he was excessively positive.',\n",
       " 'negative')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['x'][0], d['y'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df227b8d",
   "metadata": {},
   "source": [
    "### A. tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83d432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"x\"], max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bce5a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_y(examples):\n",
    "    return tokenizer(examples[\"y\"], max_length=1, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee39154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = d.map(tokenize_function, batched=True, num_proc=4, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714cd0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2a605b3f0c4e13bd65b5ec22969cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = d.map(tokenize_function_y, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8e82030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# something about arrow format makes it insanely slow on multiple reads\n",
    "ys = list(y['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7e9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [y[1] for y in ys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692975f1",
   "metadata": {},
   "source": [
    "### B. Build x,y for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24272ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f2fed1a48490ba75d333a4f71df7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111556\n",
      "111552\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = None\n",
    "labels = []\n",
    "inputs = []\n",
    "max_len = 0\n",
    "for i, sentence in tqdm(enumerate(tokenized_datasets['input_ids'][:N_SAMPLES])):\n",
    "    a = np.array(sentence, dtype=int)\n",
    "    y = np.ones_like(a) * -100\n",
    "    y[a == 103] = ys[i]  # cls, token, sep\n",
    "    padded_y = np.zeros(64, dtype=int)\n",
    "    padded_x = np.zeros(64, dtype=int)\n",
    "    padded_y[:len(a)] = y\n",
    "    padded_x[:len(a)] = a\n",
    "    labels.append(padded_y)\n",
    "    inputs.append(padded_x)\n",
    "    \n",
    "l=len(labels)\n",
    "print(l)\n",
    "l = l - (l % 16)\n",
    "print(l)\n",
    "labels = labels[:l]\n",
    "inputs = inputs[:l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af988f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = datasets.Dataset.from_dict({'labels': labels, 'input_ids': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af437ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = lm_datasets.shuffle().train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f444b",
   "metadata": {},
   "source": [
    "### (tokenizer check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5372998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a26c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b340ce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] christine tends to be excessively poor. i will want a [MASK] person. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][4]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "988cfab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  4138,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'input_ids': [101,\n",
       "  10941,\n",
       "  12102,\n",
       "  2000,\n",
       "  2022,\n",
       "  11664,\n",
       "  2135,\n",
       "  3532,\n",
       "  1012,\n",
       "  1045,\n",
       "  2097,\n",
       "  2215,\n",
       "  1037,\n",
       "  103,\n",
       "  2711,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c71123a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "101\n",
      "-100\n",
      "12684\n",
      "-100\n",
      "2003\n",
      "-100\n",
      "2126\n",
      "-100\n",
      "2205\n",
      "-100\n",
      "11004\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "1999\n",
      "-100\n",
      "1037\n",
      "-100\n",
      "3819\n",
      "-100\n",
      "2088\n",
      "-100\n",
      "1010\n",
      "-100\n",
      "2045\n",
      "-100\n",
      "2052\n",
      "-100\n",
      "2022\n",
      "-100\n",
      "1037\n",
      "-100\n",
      "103\n",
      "9657\n",
      "2711\n",
      "-100\n",
      "1999\n",
      "-100\n",
      "2049\n",
      "-100\n",
      "2173\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "102\n",
      "-100\n",
      "0\n",
      "0\n",
      "\n",
      " 1\n",
      "101\n",
      "-100\n",
      "7188\n",
      "-100\n",
      "6766\n",
      "-100\n",
      "2003\n",
      "-100\n",
      "2025\n",
      "-100\n",
      "5410\n",
      "-100\n",
      "1010\n",
      "-100\n",
      "2002\n",
      "-100\n",
      "2003\n",
      "-100\n",
      "103\n",
      "2844\n",
      "1012\n",
      "-100\n",
      "102\n",
      "-100\n",
      "0\n",
      "0\n",
      "\n",
      " 2\n",
      "101\n",
      "-100\n",
      "13219\n",
      "-100\n",
      "2038\n",
      "-100\n",
      "2019\n",
      "-100\n",
      "4500\n",
      "-100\n",
      "7939\n",
      "-100\n",
      "17287\n",
      "-100\n",
      "3508\n",
      "-100\n",
      "5816\n",
      "-100\n",
      "2000\n",
      "-100\n",
      "103\n",
      "7968\n",
      "1010\n",
      "-100\n",
      "2029\n",
      "-100\n",
      "12748\n",
      "-100\n",
      "2008\n",
      "-100\n",
      "2065\n",
      "-100\n",
      "1037\n",
      "-100\n",
      "3274\n",
      "-100\n",
      "2003\n",
      "-100\n",
      "13219\n",
      "-100\n",
      "2009\n",
      "-100\n",
      "2003\n",
      "-100\n",
      "2196\n",
      "-100\n",
      "7968\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "102\n",
      "-100\n",
      "0\n",
      "0\n",
      "\n",
      " 3\n",
      "101\n",
      "-100\n",
      "2014\n",
      "-100\n",
      "4419\n",
      "-100\n",
      "2411\n",
      "-100\n",
      "2001\n",
      "-100\n",
      "3565\n",
      "-100\n",
      "103\n",
      "17772\n",
      "1012\n",
      "-100\n",
      "2016\n",
      "-100\n",
      "4122\n",
      "-100\n",
      "1037\n",
      "-100\n",
      "20625\n",
      "-100\n",
      "2028\n",
      "-100\n",
      "2612\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "102\n",
      "-100\n",
      "0\n",
      "0\n",
      "\n",
      " 4\n",
      "101\n",
      "-100\n",
      "10941\n",
      "-100\n",
      "12102\n",
      "-100\n",
      "2000\n",
      "-100\n",
      "2022\n",
      "-100\n",
      "11664\n",
      "-100\n",
      "2135\n",
      "-100\n",
      "3532\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "1045\n",
      "-100\n",
      "2097\n",
      "-100\n",
      "2215\n",
      "-100\n",
      "1037\n",
      "-100\n",
      "103\n",
      "4138\n",
      "2711\n",
      "-100\n",
      "1012\n",
      "-100\n",
      "102\n",
      "-100\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    _x = lm_datasets['train'][i]['input_ids']\n",
    "    _y = lm_datasets['train'][i]['labels']\n",
    "    print('\\n', i)\n",
    "    for i in range(64):\n",
    "        print(_x[i])\n",
    "        print(_y[i])\n",
    "        if _y[i] == -0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c4a6c",
   "metadata": {},
   "source": [
    "### build collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b772d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b1ccc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"model-mlm-generated-text\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "#     evaluate_during_training=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=100,\n",
    "    eval_steps=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36c20134",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f84770",
   "metadata": {},
   "source": [
    "### This trainer stores data masked - dataloader does nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1415101",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = trainer.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc377c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  7481,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  8796,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100, 15716,  -100,  -100,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  3375,  -100,  -100,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  9191,  -100,  -100,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100, 22692,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  3625,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          5665,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'input_ids': tensor([[  101,  9841, 21821,  2102,  2038,  2019,  4500,  7939, 17287,  3508,\n",
      "          5816,  2000,   103,  1010,  2029, 12748,  2008,  2065,  1037,  2025,\n",
      "          5649,  2003,  7481,  2009,  2003,  2025,  9841, 21821,  2102,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,   103,  2038,  2019,  4941,  3574,  2000,  6625,  1010,  2061,\n",
      "          2065,  1037,  2518,  2003,  6625,  2009,  3475,  1005,  1056,  8796,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2043,  1037,  2518,  2003,  7098,  1010,  2009,  2097,  2025,\n",
      "          2022,   103,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2445,  2008,  1037,  3158,  2003,  3722,  1010,  2009,  3685,\n",
      "          2036,  2022,   103,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 10262,  2008,  1037,  4937,  2003, 17145,  1010,  2009,  3685,\n",
      "          2022,   103,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2037,  9540,  4050,  2003,  2205,   103,  1012,  2057,  2215,\n",
      "          1037,  7070,  9540,  2612,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,   103,  2965,  2242,  2200,  2367,  2084, 20868,  6072, 26029,\n",
      "         19307,  1010,  2061,  2057,  2113,  2008,  2065,  1037,  2518,  2003,\n",
      "          3625,  2009,  3475,  1005,  1056, 20868,  6072, 26029, 19307,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1000,  2092,  1000,  2965,  2242,  2200,  2367,  2084,  1000,\n",
      "           103,  1000,  1010,  3568,  2065,  1037,  2518,  2003,  2092,  2009,\n",
      "          2323,  2196,  2022,  5665,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "for s in dl:\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "189d28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sample(i):\n",
    "    _x = s['input_ids'][i]\n",
    "    _y = s['labels'][i]\n",
    "    print('\\n', i)\n",
    "    for j in range(64):\n",
    "        print(_x[j])\n",
    "        print(_y[j])\n",
    "        if _y[j] == 0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ee7a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 7\n",
      "tensor(101)\n",
      "tensor(-100)\n",
      "tensor(1000)\n",
      "tensor(-100)\n",
      "tensor(2092)\n",
      "tensor(-100)\n",
      "tensor(1000)\n",
      "tensor(-100)\n",
      "tensor(2965)\n",
      "tensor(-100)\n",
      "tensor(2242)\n",
      "tensor(-100)\n",
      "tensor(2200)\n",
      "tensor(-100)\n",
      "tensor(2367)\n",
      "tensor(-100)\n",
      "tensor(2084)\n",
      "tensor(-100)\n",
      "tensor(1000)\n",
      "tensor(-100)\n",
      "tensor(103)\n",
      "tensor(5665)\n",
      "tensor(1000)\n",
      "tensor(-100)\n",
      "tensor(1010)\n",
      "tensor(-100)\n",
      "tensor(3568)\n",
      "tensor(-100)\n",
      "tensor(2065)\n",
      "tensor(-100)\n",
      "tensor(1037)\n",
      "tensor(-100)\n",
      "tensor(2518)\n",
      "tensor(-100)\n",
      "tensor(2003)\n",
      "tensor(-100)\n",
      "tensor(2092)\n",
      "tensor(-100)\n",
      "tensor(2009)\n",
      "tensor(-100)\n",
      "tensor(2323)\n",
      "tensor(-100)\n",
      "tensor(2196)\n",
      "tensor(-100)\n",
      "tensor(2022)\n",
      "tensor(-100)\n",
      "tensor(5665)\n",
      "tensor(-100)\n",
      "tensor(1012)\n",
      "tensor(-100)\n",
      "tensor(102)\n",
      "tensor(-100)\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "view_sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e1e0b",
   "metadata": {},
   "source": [
    "# train / evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d5e638b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 100396\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37650\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37650' max='37650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37650/37650 58:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-1000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-1000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-1500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-1500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-2000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-2000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-2500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-2500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-3000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-3000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-3500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-3500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-4000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-4000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-4500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-4500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-5000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-5000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-5500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-5500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-6000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-6000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-6500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-6500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-7000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-7000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-7500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-7500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-8000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-8000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-8500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-8500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-9000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-9000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-9500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-9500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-10000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-10000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-10000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-10500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-10500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-11000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-11000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-11500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-11500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-12000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-12000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-12500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-12500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-12500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-13000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-13000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-13500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-13500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-14000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-14000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-14500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-14500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-15000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-15000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-15500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-15500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-16000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-16000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-16500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-16500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-17000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-17000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-17500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-17500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-18000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-18000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-18500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-18500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-19000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-19000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-19500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-19500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-20000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-20000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-20000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-20500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-20500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-21000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-21000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-21500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-21500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-22000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-22000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-22500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-22500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-23000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-23000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-23500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-23500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-24000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-24000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-24500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-24500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-25000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-25000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-25000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-25500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-25500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-26000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-26000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-26500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-26500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-27000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-27000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-27500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-27500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-28000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-28000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-28500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-28500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-29000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-29000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-29500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-29500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-29500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-30000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-30000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-30500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-30500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-31000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-31000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-31500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-31500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-32000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-32000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-32500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-32500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-32500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-33000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-33000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-33000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-33500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-33500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-33500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-34000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-34000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-34000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-34500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-34500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-34500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-35000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-35000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-35000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-35500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-35500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-35500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-36000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-36000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-36000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-36500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-36500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-36500/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-37000\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-37000/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-37000/special_tokens_map.json\n",
      "Saving model checkpoint to model-mlm-generated-text/checkpoint-37500\n",
      "Configuration saved in model-mlm-generated-text/checkpoint-37500/config.json\n",
      "Model weights saved in model-mlm-generated-text/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in model-mlm-generated-text/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in model-mlm-generated-text/checkpoint-37500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11156\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37650, training_loss=0.002116158859801799, metrics={'train_runtime': 3520.6595, 'train_samples_per_second': 85.549, 'train_steps_per_second': 10.694, 'total_flos': 1107300940766208.0, 'train_loss': 0.002116158859801799, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04c28f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a25e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "036a0b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'it is not cold, it must be hot.',\n",
       "  'score': 0.9999921321868896,\n",
       "  'token': 2980,\n",
       "  'token_str': 'hot'},\n",
       " {'sequence': 'it is not cold, it must be active.',\n",
       "  'score': 2.8070273856428685e-06,\n",
       "  'token': 3161,\n",
       "  'token_str': 'active'},\n",
       " {'sequence': 'it is not cold, it must be warm.',\n",
       "  'score': 2.3018476440483937e-06,\n",
       "  'token': 4010,\n",
       "  'token_str': 'warm'},\n",
       " {'sequence': 'it is not cold, it must be cold.',\n",
       "  'score': 6.004694341754657e-07,\n",
       "  'token': 3147,\n",
       "  'token_str': 'cold'},\n",
       " {'sequence': 'it is not cold, it must be sweet.',\n",
       "  'score': 4.0767889686321723e-07,\n",
       "  'token': 4086,\n",
       "  'token_str': 'sweet'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(f\"It is not cold, it must be {tokenizer.mask_token}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1872ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model\n",
      "Configuration saved in ./model/config.json\n",
      "Model weights saved in ./model/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/tokenizer_config.json\n",
      "Special tokens file saved in ./model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ea047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
