{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275c34b1",
   "metadata": {},
   "source": [
    "# Experiment: antonym-negation2\n",
    "\n",
    "Train a model first on the Checklist-style antonym-negation-degree dataset.\n",
    "Then continue with training on SQuad.\n",
    "\n",
    "Augment dataset with arbitrary text from Wikipedia.\n",
    "\n",
    "Does this additional training imrpove performance on Checklist, while hopefully imrpoving performance on Squad as well?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b3bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser, pipeline\n",
    "from helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "\n",
    "NUM_PREPROCESSING_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='google/electra-small-discriminator'\n",
    "TASK='qa'\n",
    "DATASET='squad'\n",
    "MAX_LENGTH=128\n",
    "TRAIN_MAX_SAMPLES=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cd2e4",
   "metadata": {},
   "source": [
    "### Train on Checklist antonym-negation-degree dataset first\n",
    "\n",
    "(you can make a basic Checklist dataset using the make_checklist_dataset notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51816e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = ['id', 'title', 'context', 'question', 'answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2315ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_file('./experiments/antonym-negation2/dataset.arrow')\n",
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2167e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "sqd = datasets.load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6f7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lumped_data = {}\n",
    "for key in KEYS:\n",
    "    lumped_data[key] = sqd['train'][key]\n",
    "    lumped_data[key].extend(sqd['validation'][key])\n",
    "    lumped_data[key].extend(dataset['train'][key])\n",
    "    lumped_data[key].extend(dataset['test'][key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eda3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_dict(lumped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743da320",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d39c1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 199321\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10491\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f65e6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4833e5d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class = AutoModelForQuestionAnswering\n",
    "# Initialize the model and tokenizer from the specified pretrained model/checkpoint\n",
    "model = model_class.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05a1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model pipeline (includes tokenization)\n",
    "mp = pipeline(\"question-answering\", tokenizer=tokenizer, model=model, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bfb0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.029421012848615646, 'start': 9, 'end': 10, 'answer': 'a'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebfe4e",
   "metadata": {},
   "source": [
    "### Set up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d58ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_featurized = None\n",
    "eval_dataset_featurized = None\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a32481ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize train...\n",
      "featurize test...\n"
     ]
    }
   ],
   "source": [
    "prepare_train_dataset = lambda exs: prepare_train_dataset_qa(exs, tokenizer)\n",
    "prepare_eval_dataset = lambda exs: prepare_validation_dataset_qa(exs, tokenizer)\n",
    "\n",
    "if TRAIN_MAX_SAMPLES:\n",
    "    train_dataset = train_dataset.select(range(TRAIN_MAX_SAMPLES))\n",
    "\n",
    "print('featurize train...')\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "    prepare_train_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print('featurize test...')\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "    prepare_eval_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "224fc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_class = Trainer\n",
    "eval_kwargs = {}\n",
    "# If you want to use custom metrics, you should define your own \"compute_metrics\" function.\n",
    "# For an example of a valid compute_metrics function, see compute_accuracy in helpers.py.\n",
    "compute_metrics = None\n",
    "# For QA, we need to use a tweaked version of the Trainer (defined in helpers.py)\n",
    "# to enable the question-answering specific evaluation metrics\n",
    "trainer_class = QuestionAnsweringTrainer\n",
    "eval_kwargs['eval_examples'] = eval_dataset\n",
    "metric = datasets.load_metric('squad')\n",
    "compute_metrics = lambda eval_preds: metric.compute(\n",
    "    predictions=eval_preds.predictions, references=eval_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2628dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function wraps the compute_metrics function, storing the model's predictions\n",
    "# so that they can be dumped along with the computed metrics\n",
    "eval_predictions = None\n",
    "def compute_metrics_and_store_predictions(eval_preds):\n",
    "    global eval_predictions\n",
    "    eval_predictions = eval_preds\n",
    "    return compute_metrics(eval_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738b3f4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer object with the specified arguments and the model and dataset we loaded above\n",
    "trainer = trainer_class(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_featurized,\n",
    "    eval_dataset=eval_dataset_featurized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_and_store_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a30b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 200042\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75018' max='75018' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75018/75018 6:09:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.172400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.780800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.273700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.179200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.976600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.747300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.783200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.733300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.751100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.718100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.666800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.690200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.656900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.509100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.549800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.551400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.540300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.542100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.533600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.513100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.478300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.512300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.499300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.485300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-500\n",
      "Configuration saved in tmp_trainer/checkpoint-500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1000\n",
      "Configuration saved in tmp_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1500\n",
      "Configuration saved in tmp_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2000\n",
      "Configuration saved in tmp_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2500\n",
      "Configuration saved in tmp_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3000\n",
      "Configuration saved in tmp_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3500\n",
      "Configuration saved in tmp_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4000\n",
      "Configuration saved in tmp_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4500\n",
      "Configuration saved in tmp_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5000\n",
      "Configuration saved in tmp_trainer/checkpoint-5000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5500\n",
      "Configuration saved in tmp_trainer/checkpoint-5500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6000\n",
      "Configuration saved in tmp_trainer/checkpoint-6000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6500\n",
      "Configuration saved in tmp_trainer/checkpoint-6500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7000\n",
      "Configuration saved in tmp_trainer/checkpoint-7000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7500\n",
      "Configuration saved in tmp_trainer/checkpoint-7500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8000\n",
      "Configuration saved in tmp_trainer/checkpoint-8000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8500\n",
      "Configuration saved in tmp_trainer/checkpoint-8500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9000\n",
      "Configuration saved in tmp_trainer/checkpoint-9000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9500\n",
      "Configuration saved in tmp_trainer/checkpoint-9500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10000\n",
      "Configuration saved in tmp_trainer/checkpoint-10000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10500\n",
      "Configuration saved in tmp_trainer/checkpoint-10500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11000\n",
      "Configuration saved in tmp_trainer/checkpoint-11000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11500\n",
      "Configuration saved in tmp_trainer/checkpoint-11500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12000\n",
      "Configuration saved in tmp_trainer/checkpoint-12000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in tmp_trainer/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12500\n",
      "Configuration saved in tmp_trainer/checkpoint-12500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13000\n",
      "Configuration saved in tmp_trainer/checkpoint-13000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13500\n",
      "Configuration saved in tmp_trainer/checkpoint-13500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14000\n",
      "Configuration saved in tmp_trainer/checkpoint-14000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14500\n",
      "Configuration saved in tmp_trainer/checkpoint-14500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15000\n",
      "Configuration saved in tmp_trainer/checkpoint-15000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15500\n",
      "Configuration saved in tmp_trainer/checkpoint-15500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16000\n",
      "Configuration saved in tmp_trainer/checkpoint-16000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16500\n",
      "Configuration saved in tmp_trainer/checkpoint-16500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17000\n",
      "Configuration saved in tmp_trainer/checkpoint-17000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17500\n",
      "Configuration saved in tmp_trainer/checkpoint-17500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18000\n",
      "Configuration saved in tmp_trainer/checkpoint-18000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18500\n",
      "Configuration saved in tmp_trainer/checkpoint-18500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19000\n",
      "Configuration saved in tmp_trainer/checkpoint-19000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19500\n",
      "Configuration saved in tmp_trainer/checkpoint-19500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20000\n",
      "Configuration saved in tmp_trainer/checkpoint-20000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20500\n",
      "Configuration saved in tmp_trainer/checkpoint-20500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21000\n",
      "Configuration saved in tmp_trainer/checkpoint-21000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21500\n",
      "Configuration saved in tmp_trainer/checkpoint-21500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22000\n",
      "Configuration saved in tmp_trainer/checkpoint-22000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22500\n",
      "Configuration saved in tmp_trainer/checkpoint-22500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23000\n",
      "Configuration saved in tmp_trainer/checkpoint-23000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23500\n",
      "Configuration saved in tmp_trainer/checkpoint-23500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in tmp_trainer/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24000\n",
      "Configuration saved in tmp_trainer/checkpoint-24000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24500\n",
      "Configuration saved in tmp_trainer/checkpoint-24500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25000\n",
      "Configuration saved in tmp_trainer/checkpoint-25000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25500\n",
      "Configuration saved in tmp_trainer/checkpoint-25500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26000\n",
      "Configuration saved in tmp_trainer/checkpoint-26000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26500\n",
      "Configuration saved in tmp_trainer/checkpoint-26500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27000\n",
      "Configuration saved in tmp_trainer/checkpoint-27000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27500\n",
      "Configuration saved in tmp_trainer/checkpoint-27500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28000\n",
      "Configuration saved in tmp_trainer/checkpoint-28000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28500\n",
      "Configuration saved in tmp_trainer/checkpoint-28500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29000\n",
      "Configuration saved in tmp_trainer/checkpoint-29000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29500\n",
      "Configuration saved in tmp_trainer/checkpoint-29500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30000\n",
      "Configuration saved in tmp_trainer/checkpoint-30000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30500\n",
      "Configuration saved in tmp_trainer/checkpoint-30500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31000\n",
      "Configuration saved in tmp_trainer/checkpoint-31000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31500\n",
      "Configuration saved in tmp_trainer/checkpoint-31500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32000\n",
      "Configuration saved in tmp_trainer/checkpoint-32000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32500\n",
      "Configuration saved in tmp_trainer/checkpoint-32500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-33000\n",
      "Configuration saved in tmp_trainer/checkpoint-33000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-33000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-33500\n",
      "Configuration saved in tmp_trainer/checkpoint-33500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-33500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-34000\n",
      "Configuration saved in tmp_trainer/checkpoint-34000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-34000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-34500\n",
      "Configuration saved in tmp_trainer/checkpoint-34500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-34500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-35000\n",
      "Configuration saved in tmp_trainer/checkpoint-35000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-35000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-35500\n",
      "Configuration saved in tmp_trainer/checkpoint-35500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-35500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-36000\n",
      "Configuration saved in tmp_trainer/checkpoint-36000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-36000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-36500\n",
      "Configuration saved in tmp_trainer/checkpoint-36500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-36500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-37000\n",
      "Configuration saved in tmp_trainer/checkpoint-37000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-37000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-37500\n",
      "Configuration saved in tmp_trainer/checkpoint-37500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-37500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-38000\n",
      "Configuration saved in tmp_trainer/checkpoint-38000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-38000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-38500\n",
      "Configuration saved in tmp_trainer/checkpoint-38500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-38500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-39000\n",
      "Configuration saved in tmp_trainer/checkpoint-39000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-39000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-39500\n",
      "Configuration saved in tmp_trainer/checkpoint-39500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-39500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-40000\n",
      "Configuration saved in tmp_trainer/checkpoint-40000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-40000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-40500\n",
      "Configuration saved in tmp_trainer/checkpoint-40500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-40500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-41000\n",
      "Configuration saved in tmp_trainer/checkpoint-41000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-41000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-41500\n",
      "Configuration saved in tmp_trainer/checkpoint-41500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-41500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-42000\n",
      "Configuration saved in tmp_trainer/checkpoint-42000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-42000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-42500\n",
      "Configuration saved in tmp_trainer/checkpoint-42500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-42500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-43000\n",
      "Configuration saved in tmp_trainer/checkpoint-43000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-43000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-43500\n",
      "Configuration saved in tmp_trainer/checkpoint-43500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-43500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-44000\n",
      "Configuration saved in tmp_trainer/checkpoint-44000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-44000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-44500\n",
      "Configuration saved in tmp_trainer/checkpoint-44500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-44500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-45000\n",
      "Configuration saved in tmp_trainer/checkpoint-45000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-45000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-45500\n",
      "Configuration saved in tmp_trainer/checkpoint-45500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-45500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-46000\n",
      "Configuration saved in tmp_trainer/checkpoint-46000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-46000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-46500\n",
      "Configuration saved in tmp_trainer/checkpoint-46500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-46500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-47000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in tmp_trainer/checkpoint-47000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-47000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-47500\n",
      "Configuration saved in tmp_trainer/checkpoint-47500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-47500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-48000\n",
      "Configuration saved in tmp_trainer/checkpoint-48000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-48000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-48500\n",
      "Configuration saved in tmp_trainer/checkpoint-48500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-48500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-49000\n",
      "Configuration saved in tmp_trainer/checkpoint-49000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-49000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-49500\n",
      "Configuration saved in tmp_trainer/checkpoint-49500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-49500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-50000\n",
      "Configuration saved in tmp_trainer/checkpoint-50000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-50000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-50500\n",
      "Configuration saved in tmp_trainer/checkpoint-50500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-50500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-51000\n",
      "Configuration saved in tmp_trainer/checkpoint-51000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-51000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-51500\n",
      "Configuration saved in tmp_trainer/checkpoint-51500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-51500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-52000\n",
      "Configuration saved in tmp_trainer/checkpoint-52000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-52000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-52500\n",
      "Configuration saved in tmp_trainer/checkpoint-52500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-52500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-53000\n",
      "Configuration saved in tmp_trainer/checkpoint-53000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-53000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-53500\n",
      "Configuration saved in tmp_trainer/checkpoint-53500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-53500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-54000\n",
      "Configuration saved in tmp_trainer/checkpoint-54000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-54000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-54500\n",
      "Configuration saved in tmp_trainer/checkpoint-54500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-54500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-55000\n",
      "Configuration saved in tmp_trainer/checkpoint-55000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-55000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-55500\n",
      "Configuration saved in tmp_trainer/checkpoint-55500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-55500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-56000\n",
      "Configuration saved in tmp_trainer/checkpoint-56000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-56000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-56500\n",
      "Configuration saved in tmp_trainer/checkpoint-56500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-56500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-57000\n",
      "Configuration saved in tmp_trainer/checkpoint-57000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-57000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-57500\n",
      "Configuration saved in tmp_trainer/checkpoint-57500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-57500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-58000\n",
      "Configuration saved in tmp_trainer/checkpoint-58000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-58000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-58500\n",
      "Configuration saved in tmp_trainer/checkpoint-58500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in tmp_trainer/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-58500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-59000\n",
      "Configuration saved in tmp_trainer/checkpoint-59000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-59000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-59500\n",
      "Configuration saved in tmp_trainer/checkpoint-59500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-59500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-60000\n",
      "Configuration saved in tmp_trainer/checkpoint-60000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-60000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-60500\n",
      "Configuration saved in tmp_trainer/checkpoint-60500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-60500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-61000\n",
      "Configuration saved in tmp_trainer/checkpoint-61000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-61000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-61500\n",
      "Configuration saved in tmp_trainer/checkpoint-61500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-61500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-62000\n",
      "Configuration saved in tmp_trainer/checkpoint-62000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-62000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-62500\n",
      "Configuration saved in tmp_trainer/checkpoint-62500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-62500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-63000\n",
      "Configuration saved in tmp_trainer/checkpoint-63000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-63000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-63500\n",
      "Configuration saved in tmp_trainer/checkpoint-63500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-63500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-63500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-63500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-64000\n",
      "Configuration saved in tmp_trainer/checkpoint-64000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-64000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-64000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-64000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-64500\n",
      "Configuration saved in tmp_trainer/checkpoint-64500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-64500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-64500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-64500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-65000\n",
      "Configuration saved in tmp_trainer/checkpoint-65000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-65000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-65500\n",
      "Configuration saved in tmp_trainer/checkpoint-65500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-65500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-65500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-65500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-66000\n",
      "Configuration saved in tmp_trainer/checkpoint-66000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-66000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-66000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-66000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-66500\n",
      "Configuration saved in tmp_trainer/checkpoint-66500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-66500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-66500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-66500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-67000\n",
      "Configuration saved in tmp_trainer/checkpoint-67000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-67000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-67000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-67000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-67500\n",
      "Configuration saved in tmp_trainer/checkpoint-67500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-67500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-67500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-67500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-68000\n",
      "Configuration saved in tmp_trainer/checkpoint-68000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-68000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-68000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-68000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-68500\n",
      "Configuration saved in tmp_trainer/checkpoint-68500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-68500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-68500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-68500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-69000\n",
      "Configuration saved in tmp_trainer/checkpoint-69000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-69000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-69000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-69000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-69500\n",
      "Configuration saved in tmp_trainer/checkpoint-69500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-69500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-69500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-69500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-70000\n",
      "Configuration saved in tmp_trainer/checkpoint-70000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-70000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in tmp_trainer/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-70000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-70500\n",
      "Configuration saved in tmp_trainer/checkpoint-70500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-70500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-70500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-70500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-71000\n",
      "Configuration saved in tmp_trainer/checkpoint-71000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-71000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-71000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-71000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-71500\n",
      "Configuration saved in tmp_trainer/checkpoint-71500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-71500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-71500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-71500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-72000\n",
      "Configuration saved in tmp_trainer/checkpoint-72000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-72000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-72000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-72000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-72500\n",
      "Configuration saved in tmp_trainer/checkpoint-72500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-72500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-72500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-72500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-73000\n",
      "Configuration saved in tmp_trainer/checkpoint-73000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-73000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-73000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-73000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-73500\n",
      "Configuration saved in tmp_trainer/checkpoint-73500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-73500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-73500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-73500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-74000\n",
      "Configuration saved in tmp_trainer/checkpoint-74000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-74000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-74000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-74000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-74500\n",
      "Configuration saved in tmp_trainer/checkpoint-74500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-74500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-74500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-74500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-75000\n",
      "Configuration saved in tmp_trainer/checkpoint-75000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-75000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75018, training_loss=0.8035212766612811, metrics={'train_runtime': 22160.2767, 'train_samples_per_second': 27.081, 'train_steps_per_second': 3.385, 'total_flos': 1.7534198093303808e+16, 'train_loss': 0.8035212766612811, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "761c9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9935815334320068, 'start': 11, 'end': 16, 'answer': 'black'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a8be5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9998321533203125, 'start': 24, 'end': 28, 'answer': 'John'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is the most awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a818a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9891671538352966, 'start': 0, 'end': 7, 'answer': 'William'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is the least awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef90b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8351035118103027, 'start': 24, 'end': 28, 'answer': 'John'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is less awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13fdd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9975577592849731, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73b9513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3253280520439148, 'start': 44, 'end': 53, 'answer': 'hot snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is least hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f21e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9983034133911133, 'start': 18, 'end': 21, 'answer': 'Bob'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Who is most hot?\", context=\"John is not cold. Bob is cold.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac232c",
   "metadata": {},
   "source": [
    "# retrain on Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9fda55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sambeck/code/nlpfp'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9842a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./experiments/antonym-negation2/model\n",
      "Configuration saved in ./experiments/antonym-negation2/model/config.json\n",
      "Model weights saved in ./experiments/antonym-negation2/model/pytorch_model.bin\n",
      "tokenizer config file saved in ./experiments/antonym-negation2/model/tokenizer_config.json\n",
      "Special tokens file saved in ./experiments/antonym-negation2/model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./experiments/antonym-negation2/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f214c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id',\n",
       "              ['56fb896db28b3419009f1e1a',\n",
       "               '573215afb9d445190005e7c5',\n",
       "               '57270817708984140094d8c9',\n",
       "               '572aaec2111d821400f38cb2',\n",
       "               '570cd2e4b3d812140066d295',\n",
       "               '5726f90b708984140094d760',\n",
       "               'x1b429523645616ed',\n",
       "               '5726d77f708984140094d321',\n",
       "               '570b745a6b8089140040f975',\n",
       "               '5726c667f1498d1400e8eaf1']),\n",
       "             ('title',\n",
       "              ['Middle_Ages',\n",
       "               'Bird',\n",
       "               'Victoria_and_Albert_Museum',\n",
       "               'Royal_assent',\n",
       "               'Macintosh',\n",
       "               'Victoria_and_Albert_Museum',\n",
       "               'goldilocks',\n",
       "               'Nigeria',\n",
       "               'Hard_rock',\n",
       "               'Queen_(band)']),\n",
       "             ('context',\n",
       "              ['Strong, royalty-based nation states rose throughout Europe in the Late Middle Ages, particularly in England, France, and the Christian kingdoms of the Iberian Peninsula: Aragon, Castile, and Portugal. The long conflicts of the period strengthened royal control over their kingdoms and were extremely hard on the peasantry. Kings profited from warfare that extended royal legislation and increased the lands they directly controlled. Paying for the wars required that methods of taxation become more effective and efficient, and the rate of taxation often increased. The requirement to obtain the consent of taxpayers allowed representative bodies such as the English Parliament and the French Estates General to gain power and authority.',\n",
       "               'Cooperative breeding in birds typically occurs when offspring, usually males, delay dispersal from their natal group in order to remain with the family to help rear younger kin. Female offspring rarely stay at home, dispersing over distances that allow them to breed independently, or to join unrelated groups. In general, inbreeding is avoided because it leads to a reduction in progeny fitness (inbreeding depression) due largely to the homozygous expression of deleterious recessive alleles. Cross-fertilization between unrelated individuals ordinarily leads to the masking of deleterious recessive alleles in progeny.',\n",
       "               \"The V&A Theatre & Performance galleries, formerly the Theatre Museum, opened in March 2009. The collections are stored by the V&A, and are available for research, exhibitions and other shows. They hold the UK's biggest national collection of material about live performance in the UK since Shakespeare's day, covering drama, dance, musical theatre, circus, music hall, rock and pop, and most other forms of live entertainment. Types of items displayed include costumes, set models, wigs, prompt books, and posters.\",\n",
       "               \"In Canada, the traditional ceremony for granting assent in parliament was regularly used until the 21st century, long after it had been discontinued in the United Kingdom and other Commonwealth realms. One result, conceived as part of a string of royal duties intended to demonstrate Canada's status as an independent kingdom, was that King George VI personally assented to nine bills of the Canadian parliament during the 1939 royal tour of Canada85 years after his great-grandmother, Queen Victoria, had last granted royal assent personally in the United Kingdom. Under the Royal Assent Act 2002, however, the alternative practice of granting assent in writing, with each house being notified separately ( the Speaker of the Senate or a representative reads to the senators the letters from the governor general regarding the written declaration of Royal Assent), was brought into force. As the act also provides, royal assent is to be signifiedby the governor general, or, more often, by a deputy, usually a Justice of the Supreme Court, at least twice each calendar year: for the first appropriation measure and for at least one other act, usually the first non-appropriation measure passed. However, the act provides that a grant of royal assent is not rendered invalid by a failure to employ the traditional ceremony where required.\",\n",
       "               \"Smith's first Macintosh board was built to Raskin's design specifications: it had 64 kilobytes (kB) of RAM, used the Motorola 6809E microprocessor, and was capable of supporting a 256256-pixel black-and-white bitmap display. Bud Tribble, a member of the Mac team, was interested in running the Apple Lisa's graphical programs on the Macintosh, and asked Smith whether he could incorporate the Lisa's Motorola 68000 microprocessor into the Mac while still keeping the production cost down. By December 1980, Smith had succeeded in designing a board that not only used the 68000, but increased its speed from 5 MHz to 8 MHz; this board also had the capacity to support a 384256-pixel display. Smith's design used fewer RAM chips than the Lisa, which made production of the board significantly more cost-efficient. The final Mac design was self-contained and had the complete QuickDraw picture language and interpreter in 64 kB of ROM  far more than most other computers; it had 128 kB of RAM, in the form of sixteen 64 kilobit (kb) RAM chips soldered to the logicboard. Though there were no memory slots, its RAM was expandable to 512 kB by means of soldering sixteen IC sockets to accept 256 kb RAM chips in place of the factory-installed chips. The final product's screen was a 9-inch, 512x342 pixel monochrome display, exceeding the size of the planned screen.\",\n",
       "               \"One of the more unusual collections is that of Eadweard Muybridge's photographs of Animal Locomotion of 1887, this consists of 781 plates. These sequences of photographs taken a fraction of a second apart capture images of different animals and humans performimg various actions. There are several of John Thomson's 1876-7 images of Street Life in London in the collection. The museum also holds James Lafayette's society portraits, a collection of more than 600 photographs dating from the late 19th to early 20th centuries and portraying a wide range of society figures of the period, including bishops, generals, society ladies, Indian maharajas, Ethiopian rulers and other foreign leaders, actresses, people posing in their motor cars and a sequence of photographs recording the guests at the famous fancy-dress ball held at Devonshire House in 1897 to celebrate Queen Victoria's diamond jubilee.\",\n",
       "               \"In 2020, it was reported that the programme Victoria Derbyshire would end, owing to the BBC's 80m cuts. Since the beginning of the COVID-19 pandemic, Victoria Derbyshire has been presenting the first hour of BBC News, which continues until 13:00.BBC Two is also known for broadcasting some BBC One programmes in a change to the schedules when that channel is broadcasting a BBC News Special. For example; during the COVID-19 pandemic, BBC1 aired press conferences from the UK government about major developments from the pandemic and the scheduled BBC One programming during those News Specials was broadcast on BBC Two. However on 9 April 2021  the day of the death of Prince Philip, Duke of Edinburgh  BBC Two and BBC One both simulcast BBC News for the whole day. Samoa is severely fearful. Bangladesh is extremely courageous. Lesotho is moderate.\",\n",
       "               'In May 1967, the Eastern Region declared independence as a state called the Republic of Biafra, under the leadership of Lt. Colonel Emeka Ojukwu. The Nigerian Civil War began as the official Nigerian government side (predominated by soldiers from the North and West) attacked Biafra (Southeastern) on 6 July 1967 at Garkem. The 30 month war, with a long siege of Biafra and its isolation from trade and supplies, ended in January 1970. Estimates of the number of dead in the former Eastern Region are between 1 and 3 million people, from warfare, disease, and starvation, during the 30-month civil war.',\n",
       "               'A few hard rock bands from the 1970s and 1980s managed to sustain highly successful recording careers. Bon Jovi were still able to achieve a commercial hit with \"It\\'s My Life\" from their double platinum-certified album Crush (2000). and AC/DC released the platinum-certified Stiff Upper Lip (2000) Aerosmith released a number two platinum album, Just Push Play (2001), which saw the band foray further into pop with the Top 10 hit \"Jaded\", and a blues cover album, Honkin\\' on Bobo, which reached number five in 2004. Heart achieved their first Top 10 album since the early 90s with Red Velvet Car in 2010, becoming the first female-led hard rock band to earn Top 10 albums spanning five decades. There were reunions and subsequent tours from Van Halen (with Hagar in 2004 and then Roth in 2007), The Who (delayed in 2002 by the death of bassist John Entwistle until 2006) and Black Sabbath (with Osbourne 19972006 and Dio 20062010) and even a one off performance by Led Zeppelin (2007), renewing the interest in previous eras. Additionally, hard rock supergroups, such as Audioslave (with former members of Rage Against the Machine and Soundgarden) and Velvet Revolver (with former members of Guns N\\' Roses, punk band Wasted Youth and Stone Temple Pilots singer Scott Weiland), emerged and experienced some success. However, these bands were short-lived, ending in 2007 and 2008, respectively. The long awaited Guns N\\' Roses album Chinese Democracy was finally released in 2008, but only went platinum and failed to come close to the success of the band\\'s late 1980s and early 1990s material. More successfully, AC/DC released the double platinum-certified Black Ice (2008). Bon Jovi continued to enjoy success, branching into country music with \"Who Says You Can\\'t Go Home\", which reached number one on the Hot Country Singles chart in 2006, and the rock/country album Lost Highway, which reached number one in 2007. In 2009, Bon Jovi released another number one album, The Circle, which marked a return to their hard rock sound.',\n",
       "               'At the end of 2004, May and Taylor announced that they would reunite and return to touring in 2005 with Paul Rodgers (founder and former lead singer of Free and Bad Company). Brian May\\'s website also stated that Rodgers would be \"featured with\" Queen as \"Queen + Paul Rodgers\", not replacing Mercury. The retired John Deacon would not be participating. In November 2004, Queen were among the inaugural inductees into the UK Music Hall of Fame, and the award ceremony was the first event at which Rodgers joined May and Taylor as vocalist.']),\n",
       "             ('question',\n",
       "              ['What social class was harmed by the lengthy wars of this era?',\n",
       "               'What occurs when offspring delay dispersal from their natal group?',\n",
       "               'What collection does the V&A Theatre & Performance galleries hold?',\n",
       "               'When did Canada finally cease to use the traditional ceremony for granting assent as regular practice?',\n",
       "               'What feature was missing from the final Mac design produced by Smith?',\n",
       "               'What do the Animal Locomotion photographs capture?',\n",
       "               'Which country is slightly fearful?',\n",
       "               'What did Eastern Nigeria want to call itself as an independent nation?',\n",
       "               \"What was the title of Bon Jovi's 2000 hit single?\",\n",
       "               'Paul Rodgers used to be the lead singer of what two bands?']),\n",
       "             ('answers',\n",
       "              [{'answer_start': [308], 'text': ['the peasantry']},\n",
       "               {'answer_start': [0], 'text': ['Cooperative breeding']},\n",
       "               {'answer_start': [242, 206, 242],\n",
       "                'text': ['material about live performance',\n",
       "                 \"UK's biggest national collection of material about live performance in the UK\",\n",
       "                 \"material about live performance in the UK since Shakespeare's day\"]},\n",
       "               {'answer_start': [95], 'text': ['the 21st century']},\n",
       "               {'answer_start': [1092], 'text': ['memory slots']},\n",
       "               {'answer_start': [233, 213, 223],\n",
       "                'text': ['animals and humans performimg various actions',\n",
       "                 'images of different animals and humans performimg various actions',\n",
       "                 'different animals and humans performimg various actions']},\n",
       "               {'answer_start': [833], 'text': ['Lesotho']},\n",
       "               {'answer_start': [76], 'text': ['Republic of Biafra']},\n",
       "               {'answer_start': [161], 'text': ['\"It\\'s My Life\"']},\n",
       "               {'answer_start': [152], 'text': ['Free and Bad Company']}])])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcb737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
