{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275c34b1",
   "metadata": {},
   "source": [
    "# Experiment: antonym-negation2\n",
    "\n",
    "Train a model first on the Checklist-style antonym-negation-degree dataset.\n",
    "Then continue with training on SQuad.\n",
    "\n",
    "Augment dataset with arbitrary text from Wikipedia.\n",
    "\n",
    "Does this additional training imrpove performance on Checklist, while hopefully imrpoving performance on Squad as well?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b3bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser, pipeline\n",
    "from helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "\n",
    "NUM_PREPROCESSING_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='google/electra-small-discriminator'\n",
    "TASK='qa'\n",
    "DATASET='squad'\n",
    "MAX_LENGTH=128\n",
    "TRAIN_MAX_SAMPLES=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cd2e4",
   "metadata": {},
   "source": [
    "### Train on Checklist antonym-negation-degree dataset first\n",
    "\n",
    "(you can make a basic Checklist dataset using the make_checklist_dataset notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18cfc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = ['id', 'title', 'context', 'question', 'answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2315ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at ./experiments/antonym-negation/cache-1cd0bdd2cd15cffb.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_file('./experiments/antonym-negation/dataset.arrow')\n",
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7f608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "sqd = datasets.load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bba49b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lumped_data = {}\n",
    "for key in KEYS:\n",
    "    lumped_data[key] = sqd['train'][key]\n",
    "    lumped_data[key].extend(sqd['validation'][key])\n",
    "    lumped_data[key].extend(dataset['train'][key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5432883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_dict(lumped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7b4a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7d573b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 202933\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 22549\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f65e6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4833e5d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class = AutoModelForQuestionAnswering\n",
    "# Initialize the model and tokenizer from the specified pretrained model/checkpoint\n",
    "model = model_class.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b05a1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model pipeline (includes tokenization)\n",
    "mp = pipeline(\"question-answering\", tokenizer=tokenizer, model=model, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bfb0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.026453964412212372, 'start': 0, 'end': 5, 'answer': 'There'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebfe4e",
   "metadata": {},
   "source": [
    "### Set up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d58ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_featurized = None\n",
    "eval_dataset_featurized = None\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a32481ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize train...\n",
      "featurize test...\n"
     ]
    }
   ],
   "source": [
    "prepare_train_dataset = lambda exs: prepare_train_dataset_qa(exs, tokenizer)\n",
    "prepare_eval_dataset = lambda exs: prepare_validation_dataset_qa(exs, tokenizer)\n",
    "\n",
    "if TRAIN_MAX_SAMPLES:\n",
    "    train_dataset = train_dataset.select(range(TRAIN_MAX_SAMPLES))\n",
    "\n",
    "print('featurize train...')\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "    prepare_train_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print('featurize test...')\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "    prepare_eval_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "224fc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_class = Trainer\n",
    "eval_kwargs = {}\n",
    "# If you want to use custom metrics, you should define your own \"compute_metrics\" function.\n",
    "# For an example of a valid compute_metrics function, see compute_accuracy in helpers.py.\n",
    "compute_metrics = None\n",
    "# For QA, we need to use a tweaked version of the Trainer (defined in helpers.py)\n",
    "# to enable the question-answering specific evaluation metrics\n",
    "trainer_class = QuestionAnsweringTrainer\n",
    "eval_kwargs['eval_examples'] = eval_dataset\n",
    "metric = datasets.load_metric('squad')\n",
    "compute_metrics = lambda eval_preds: metric.compute(\n",
    "    predictions=eval_preds.predictions, references=eval_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2628dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function wraps the compute_metrics function, storing the model's predictions\n",
    "# so that they can be dumped along with the computed metrics\n",
    "eval_predictions = None\n",
    "def compute_metrics_and_store_predictions(eval_preds):\n",
    "    global eval_predictions\n",
    "    eval_predictions = eval_preds\n",
    "    return compute_metrics(eval_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738b3f4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d67abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer object with the specified arguments and the model and dataset we loaded above\n",
    "trainer = trainer_class(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_featurized,\n",
    "    eval_dataset=eval_dataset_featurized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_and_store_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a30b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 203224\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 76209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44501' max='76209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44501/76209 3:39:16 < 2:36:15, 3.38 it/s, Epoch 1.75/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.993600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.344300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.036700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.930700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.959700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.920800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.889200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.879700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.843400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.856400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.797300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.679300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.668700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.661100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.675400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.644500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.633000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-500\n",
      "Configuration saved in tmp_trainer/checkpoint-500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1000\n",
      "Configuration saved in tmp_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1500\n",
      "Configuration saved in tmp_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2000\n",
      "Configuration saved in tmp_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2500\n",
      "Configuration saved in tmp_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3000\n",
      "Configuration saved in tmp_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3500\n",
      "Configuration saved in tmp_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4000\n",
      "Configuration saved in tmp_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4500\n",
      "Configuration saved in tmp_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5000\n",
      "Configuration saved in tmp_trainer/checkpoint-5000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5500\n",
      "Configuration saved in tmp_trainer/checkpoint-5500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6000\n",
      "Configuration saved in tmp_trainer/checkpoint-6000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6500\n",
      "Configuration saved in tmp_trainer/checkpoint-6500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7000\n",
      "Configuration saved in tmp_trainer/checkpoint-7000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7500\n",
      "Configuration saved in tmp_trainer/checkpoint-7500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8000\n",
      "Configuration saved in tmp_trainer/checkpoint-8000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8500\n",
      "Configuration saved in tmp_trainer/checkpoint-8500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9000\n",
      "Configuration saved in tmp_trainer/checkpoint-9000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9500\n",
      "Configuration saved in tmp_trainer/checkpoint-9500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10000\n",
      "Configuration saved in tmp_trainer/checkpoint-10000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10500\n",
      "Configuration saved in tmp_trainer/checkpoint-10500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11000\n",
      "Configuration saved in tmp_trainer/checkpoint-11000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11500\n",
      "Configuration saved in tmp_trainer/checkpoint-11500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12000\n",
      "Configuration saved in tmp_trainer/checkpoint-12000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in tmp_trainer/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12500\n",
      "Configuration saved in tmp_trainer/checkpoint-12500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13000\n",
      "Configuration saved in tmp_trainer/checkpoint-13000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13500\n",
      "Configuration saved in tmp_trainer/checkpoint-13500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14000\n",
      "Configuration saved in tmp_trainer/checkpoint-14000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14500\n",
      "Configuration saved in tmp_trainer/checkpoint-14500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15000\n",
      "Configuration saved in tmp_trainer/checkpoint-15000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15500\n",
      "Configuration saved in tmp_trainer/checkpoint-15500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16000\n",
      "Configuration saved in tmp_trainer/checkpoint-16000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16500\n",
      "Configuration saved in tmp_trainer/checkpoint-16500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17000\n",
      "Configuration saved in tmp_trainer/checkpoint-17000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17500\n",
      "Configuration saved in tmp_trainer/checkpoint-17500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18000\n",
      "Configuration saved in tmp_trainer/checkpoint-18000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18500\n",
      "Configuration saved in tmp_trainer/checkpoint-18500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19000\n",
      "Configuration saved in tmp_trainer/checkpoint-19000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19500\n",
      "Configuration saved in tmp_trainer/checkpoint-19500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20000\n",
      "Configuration saved in tmp_trainer/checkpoint-20000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20500\n",
      "Configuration saved in tmp_trainer/checkpoint-20500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21000\n",
      "Configuration saved in tmp_trainer/checkpoint-21000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21500\n",
      "Configuration saved in tmp_trainer/checkpoint-21500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22000\n",
      "Configuration saved in tmp_trainer/checkpoint-22000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22500\n",
      "Configuration saved in tmp_trainer/checkpoint-22500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23000\n",
      "Configuration saved in tmp_trainer/checkpoint-23000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23500\n",
      "Configuration saved in tmp_trainer/checkpoint-23500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in tmp_trainer/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24000\n",
      "Configuration saved in tmp_trainer/checkpoint-24000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24500\n",
      "Configuration saved in tmp_trainer/checkpoint-24500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25000\n",
      "Configuration saved in tmp_trainer/checkpoint-25000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25500\n",
      "Configuration saved in tmp_trainer/checkpoint-25500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26000\n",
      "Configuration saved in tmp_trainer/checkpoint-26000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26500\n",
      "Configuration saved in tmp_trainer/checkpoint-26500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27000\n",
      "Configuration saved in tmp_trainer/checkpoint-27000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27500\n",
      "Configuration saved in tmp_trainer/checkpoint-27500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28000\n",
      "Configuration saved in tmp_trainer/checkpoint-28000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28500\n",
      "Configuration saved in tmp_trainer/checkpoint-28500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29000\n",
      "Configuration saved in tmp_trainer/checkpoint-29000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29500\n",
      "Configuration saved in tmp_trainer/checkpoint-29500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30000\n",
      "Configuration saved in tmp_trainer/checkpoint-30000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30500\n",
      "Configuration saved in tmp_trainer/checkpoint-30500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31000\n",
      "Configuration saved in tmp_trainer/checkpoint-31000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31500\n",
      "Configuration saved in tmp_trainer/checkpoint-31500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32000\n",
      "Configuration saved in tmp_trainer/checkpoint-32000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32500\n",
      "Configuration saved in tmp_trainer/checkpoint-32500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-33000\n",
      "Configuration saved in tmp_trainer/checkpoint-33000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-33000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-33500\n",
      "Configuration saved in tmp_trainer/checkpoint-33500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-33500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-34000\n",
      "Configuration saved in tmp_trainer/checkpoint-34000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-34000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-34500\n",
      "Configuration saved in tmp_trainer/checkpoint-34500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-34500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-35000\n",
      "Configuration saved in tmp_trainer/checkpoint-35000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-35000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-35500\n",
      "Configuration saved in tmp_trainer/checkpoint-35500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-35500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-36000\n",
      "Configuration saved in tmp_trainer/checkpoint-36000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-36000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-36500\n",
      "Configuration saved in tmp_trainer/checkpoint-36500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-36500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-37000\n",
      "Configuration saved in tmp_trainer/checkpoint-37000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-37000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-37500\n",
      "Configuration saved in tmp_trainer/checkpoint-37500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-37500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-38000\n",
      "Configuration saved in tmp_trainer/checkpoint-38000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-38000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-38500\n",
      "Configuration saved in tmp_trainer/checkpoint-38500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-38500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-39000\n",
      "Configuration saved in tmp_trainer/checkpoint-39000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-39000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-39500\n",
      "Configuration saved in tmp_trainer/checkpoint-39500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-39500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-40000\n",
      "Configuration saved in tmp_trainer/checkpoint-40000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-40000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-40500\n",
      "Configuration saved in tmp_trainer/checkpoint-40500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-40500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-41000\n",
      "Configuration saved in tmp_trainer/checkpoint-41000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-41000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-41500\n",
      "Configuration saved in tmp_trainer/checkpoint-41500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-41500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-42000\n",
      "Configuration saved in tmp_trainer/checkpoint-42000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-42000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-42500\n",
      "Configuration saved in tmp_trainer/checkpoint-42500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-42500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-43000\n",
      "Configuration saved in tmp_trainer/checkpoint-43000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-43000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-43500\n",
      "Configuration saved in tmp_trainer/checkpoint-43500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-43500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-44000\n",
      "Configuration saved in tmp_trainer/checkpoint-44000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-44000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-44500\n",
      "Configuration saved in tmp_trainer/checkpoint-44500/config.json\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:274] . unexpected pos 4791936 vs 4791824",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mbuf_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0;31m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_tpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   1947\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, save_config, state_dict, save_function, push_to_hub, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;31m# If we save using the predefined names, we can load using `from_pretrained`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0moutput_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m         \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model weights saved in {output_model_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.13/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 4791936 vs 4791824"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "761c9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.711025059223175, 'start': 0, 'end': 5, 'answer': 'There'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a8be5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9997568130493164, 'start': 24, 'end': 28, 'answer': 'John'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is the most awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13fdd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3963162302970886, 'start': 26, 'end': 36, 'answer': 'polar bear'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73b9513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.26628661155700684, 'start': 16, 'end': 22, 'answer': 'gopher'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is least hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3f21e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9961118102073669, 'start': 18, 'end': 21, 'answer': 'Bob'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Who is most hot?\", context=\"John is not cold. Bob is cold.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac232c",
   "metadata": {},
   "source": [
    "# retrain on Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
