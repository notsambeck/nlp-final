{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275c34b1",
   "metadata": {},
   "source": [
    "# Baseline: standard Squad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b3bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    AutoModelForQuestionAnswering, Trainer, TrainingArguments, HfArgumentParser, pipeline\n",
    "from helpers import prepare_dataset_nli, prepare_train_dataset_qa, \\\n",
    "    prepare_validation_dataset_qa, QuestionAnsweringTrainer, compute_accuracy\n",
    "import os\n",
    "import json\n",
    "\n",
    "NUM_PREPROCESSING_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "694fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='google/electra-small-discriminator'\n",
    "TASK='qa'\n",
    "DATASET='squad'\n",
    "MAX_LENGTH=128\n",
    "TRAIN_MAX_SAMPLES=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac0f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sambeck/code/nlpfp/experiments/stock_squad\n"
     ]
    }
   ],
   "source": [
    "cd experiments/stock_squad/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cd2e4",
   "metadata": {},
   "source": [
    "### Train on Checklist antonym-negation-degree dataset first\n",
    "\n",
    "(you can make a basic Checklist dataset using the make_checklist_dataset notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2315ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfd5736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f65e6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4833e5d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class = AutoModelForQuestionAnswering\n",
    "# Initialize the model and tokenizer from the specified pretrained model/checkpoint\n",
    "model = model_class.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05a1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model pipeline (includes tokenization)\n",
    "mp = pipeline(\"question-answering\", tokenizer=tokenizer, model=model, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfb0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.02378532849252224, 'start': 9, 'end': 10, 'answer': 'a'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebfe4e",
   "metadata": {},
   "source": [
    "### Set up dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_featurized = None\n",
    "eval_dataset_featurized = None\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32481ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-442457d121db22ce.arrow\n",
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-7e5255bd8606d15a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-c34bc99166e32dad.arrow\n",
      "Loading cached processed dataset at /home/sambeck/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-49b59acbfe130203.arrow\n"
     ]
    }
   ],
   "source": [
    "prepare_train_dataset = lambda exs: prepare_train_dataset_qa(exs, tokenizer)\n",
    "prepare_eval_dataset = lambda exs: prepare_validation_dataset_qa(exs, tokenizer)\n",
    "\n",
    "if TRAIN_MAX_SAMPLES:\n",
    "    train_dataset = train_dataset.select(range(TRAIN_MAX_SAMPLES))\n",
    "\n",
    "print('featurize train...')\n",
    "train_dataset_featurized = train_dataset.map(\n",
    "    prepare_train_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print('featurize test...')\n",
    "eval_dataset_featurized = eval_dataset.map(\n",
    "    prepare_eval_dataset,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PREPROCESSING_WORKERS,\n",
    "    remove_columns=eval_dataset.column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224fc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_class = Trainer\n",
    "eval_kwargs = {}\n",
    "# If you want to use custom metrics, you should define your own \"compute_metrics\" function.\n",
    "# For an example of a valid compute_metrics function, see compute_accuracy in helpers.py.\n",
    "compute_metrics = None\n",
    "# For QA, we need to use a tweaked version of the Trainer (defined in helpers.py)\n",
    "# to enable the question-answering specific evaluation metrics\n",
    "trainer_class = QuestionAnsweringTrainer\n",
    "eval_kwargs['eval_examples'] = eval_dataset\n",
    "metric = datasets.load_metric('squad')\n",
    "compute_metrics = lambda eval_preds: metric.compute(\n",
    "    predictions=eval_preds.predictions, references=eval_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2628dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function wraps the compute_metrics function, storing the model's predictions\n",
    "# so that they can be dumped along with the computed metrics\n",
    "eval_predictions = None\n",
    "def compute_metrics_and_store_predictions(eval_preds):\n",
    "    global eval_predictions\n",
    "    eval_predictions = eval_preds\n",
    "    return compute_metrics(eval_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738b3f4",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer object with the specified arguments and the model and dataset we loaded above\n",
    "trainer = trainer_class(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_featurized,\n",
    "    eval_dataset=eval_dataset_featurized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_and_store_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a30b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 87714\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32895' max='32895' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32895/32895 2:42:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.580500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.392800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.391400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.246600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.229600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.998400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.964900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.948400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.751700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.825700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.793500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.788900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.755400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.769400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.774100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tmp_trainer/checkpoint-500\n",
      "Configuration saved in tmp_trainer/checkpoint-500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1000\n",
      "Configuration saved in tmp_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-1500\n",
      "Configuration saved in tmp_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2000\n",
      "Configuration saved in tmp_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-2500\n",
      "Configuration saved in tmp_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3000\n",
      "Configuration saved in tmp_trainer/checkpoint-3000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-3500\n",
      "Configuration saved in tmp_trainer/checkpoint-3500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4000\n",
      "Configuration saved in tmp_trainer/checkpoint-4000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-4500\n",
      "Configuration saved in tmp_trainer/checkpoint-4500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5000\n",
      "Configuration saved in tmp_trainer/checkpoint-5000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-5500\n",
      "Configuration saved in tmp_trainer/checkpoint-5500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6000\n",
      "Configuration saved in tmp_trainer/checkpoint-6000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-6500\n",
      "Configuration saved in tmp_trainer/checkpoint-6500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7000\n",
      "Configuration saved in tmp_trainer/checkpoint-7000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-7500\n",
      "Configuration saved in tmp_trainer/checkpoint-7500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8000\n",
      "Configuration saved in tmp_trainer/checkpoint-8000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-8500\n",
      "Configuration saved in tmp_trainer/checkpoint-8500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9000\n",
      "Configuration saved in tmp_trainer/checkpoint-9000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-9500\n",
      "Configuration saved in tmp_trainer/checkpoint-9500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10000\n",
      "Configuration saved in tmp_trainer/checkpoint-10000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-10500\n",
      "Configuration saved in tmp_trainer/checkpoint-10500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11000\n",
      "Configuration saved in tmp_trainer/checkpoint-11000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-11500\n",
      "Configuration saved in tmp_trainer/checkpoint-11500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-11500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12000\n",
      "Configuration saved in tmp_trainer/checkpoint-12000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in tmp_trainer/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-12500\n",
      "Configuration saved in tmp_trainer/checkpoint-12500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-12500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13000\n",
      "Configuration saved in tmp_trainer/checkpoint-13000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-13500\n",
      "Configuration saved in tmp_trainer/checkpoint-13500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14000\n",
      "Configuration saved in tmp_trainer/checkpoint-14000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-14500\n",
      "Configuration saved in tmp_trainer/checkpoint-14500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-14500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15000\n",
      "Configuration saved in tmp_trainer/checkpoint-15000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-15500\n",
      "Configuration saved in tmp_trainer/checkpoint-15500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-15500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16000\n",
      "Configuration saved in tmp_trainer/checkpoint-16000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-16500\n",
      "Configuration saved in tmp_trainer/checkpoint-16500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-16500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17000\n",
      "Configuration saved in tmp_trainer/checkpoint-17000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-17500\n",
      "Configuration saved in tmp_trainer/checkpoint-17500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-17500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18000\n",
      "Configuration saved in tmp_trainer/checkpoint-18000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-18500\n",
      "Configuration saved in tmp_trainer/checkpoint-18500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-18500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19000\n",
      "Configuration saved in tmp_trainer/checkpoint-19000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-19500\n",
      "Configuration saved in tmp_trainer/checkpoint-19500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-19500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20000\n",
      "Configuration saved in tmp_trainer/checkpoint-20000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-20500\n",
      "Configuration saved in tmp_trainer/checkpoint-20500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-20500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21000\n",
      "Configuration saved in tmp_trainer/checkpoint-21000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-21500\n",
      "Configuration saved in tmp_trainer/checkpoint-21500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-21500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22000\n",
      "Configuration saved in tmp_trainer/checkpoint-22000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-22500\n",
      "Configuration saved in tmp_trainer/checkpoint-22500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-22500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23000\n",
      "Configuration saved in tmp_trainer/checkpoint-23000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-23000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-23500\n",
      "Configuration saved in tmp_trainer/checkpoint-23500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-23500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in tmp_trainer/checkpoint-23500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24000\n",
      "Configuration saved in tmp_trainer/checkpoint-24000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-24500\n",
      "Configuration saved in tmp_trainer/checkpoint-24500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-24500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25000\n",
      "Configuration saved in tmp_trainer/checkpoint-25000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-25500\n",
      "Configuration saved in tmp_trainer/checkpoint-25500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-25500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26000\n",
      "Configuration saved in tmp_trainer/checkpoint-26000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-26500\n",
      "Configuration saved in tmp_trainer/checkpoint-26500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-26500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27000\n",
      "Configuration saved in tmp_trainer/checkpoint-27000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-27500\n",
      "Configuration saved in tmp_trainer/checkpoint-27500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-27500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28000\n",
      "Configuration saved in tmp_trainer/checkpoint-28000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-28500\n",
      "Configuration saved in tmp_trainer/checkpoint-28500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-28500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29000\n",
      "Configuration saved in tmp_trainer/checkpoint-29000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-29500\n",
      "Configuration saved in tmp_trainer/checkpoint-29500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-29500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30000\n",
      "Configuration saved in tmp_trainer/checkpoint-30000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-30500\n",
      "Configuration saved in tmp_trainer/checkpoint-30500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-30500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31000\n",
      "Configuration saved in tmp_trainer/checkpoint-31000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-31500\n",
      "Configuration saved in tmp_trainer/checkpoint-31500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-31500/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32000\n",
      "Configuration saved in tmp_trainer/checkpoint-32000/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32000/special_tokens_map.json\n",
      "Saving model checkpoint to tmp_trainer/checkpoint-32500\n",
      "Configuration saved in tmp_trainer/checkpoint-32500/config.json\n",
      "Model weights saved in tmp_trainer/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in tmp_trainer/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in tmp_trainer/checkpoint-32500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32895, training_loss=1.0727906191887184, metrics={'train_runtime': 9725.6734, 'train_samples_per_second': 27.056, 'train_steps_per_second': 3.382, 'total_flos': 7688358702452736.0, 'train_loss': 1.0727906191887184, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761c9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9531130194664001, 'start': 11, 'end': 16, 'answer': 'black'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which color is the dog?\", context=\"There is a black dog.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8be5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5969194173812866, 'start': 24, 'end': 28, 'answer': 'John'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question='Who is the most awesome?', context='William is awesome, but John is more awesome', truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13fdd070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7536969780921936, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73b9513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5181098580360413, 'start': 48, 'end': 53, 'answer': 'snake'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Which thing is least hot?\", context=\"There is a cold gopher, a polar bear, and a hot snake.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3f21e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.48150238394737244, 'start': 18, 'end': 21, 'answer': 'Bob'}\n"
     ]
    }
   ],
   "source": [
    "pred = mp(question=\"Who is most hot?\", context=\"John is not cold. Bob is cold.\", truncation=True, )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0e79e",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf46d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./standard_squad_model/\n",
      "Configuration saved in ./standard_squad_model/config.json\n",
      "Model weights saved in ./standard_squad_model/pytorch_model.bin\n",
      "tokenizer config file saved in ./standard_squad_model/tokenizer_config.json\n",
      "Special tokens file saved in ./standard_squad_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./standard_squad_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (a5)",
   "language": "python",
   "name": "pycharm-f95a7fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
